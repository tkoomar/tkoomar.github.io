[{"authors":["tanner"],"categories":null,"content":"I study the genetic intersection of language development and the cognitive functions underlying neuropsychiatric conditions. I rely on a variety of computational and statistical tools like machine learning and cloud infrastructure. I am also passionate about communicating science and the duty of scientists to thoughtfully share their research the rest of society.\n","date":1579219200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1579219200,"objectID":"e83c65b8f9f38577f6c5ff18ba0e6f97","permalink":"/authors/tanner/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/tanner/","section":"authors","summary":"I study the genetic intersection of language development and the cognitive functions underlying neuropsychiatric conditions. I rely on a variety of computational and statistical tools like machine learning and cloud infrastructure. I am also passionate about communicating science and the duty of scientists to thoughtfully share their research the rest of society.","tags":null,"title":"Tanner Koomar","type":"authors"},{"authors":null,"categories":["tidytuesday"],"content":"Dip into the new ggttext package to get some rich text formatting in a plot\u0026rsquo;s title. Also: sports.\n  Load in data   The question: to super bowl winners have harder schedules?   Summarize data   Test the difference in schedule strength   Plot   Bonus: Color by Team Name   Bonus: What is the bump in attendance the year after winning a superbowl?   Load in data attendance \u0026lt;- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-04/attendance.csv', col_types = cols()) glimpse(attendance)  ## Observations: 10,846 ## Variables: 8 ## $ team \u0026lt;chr\u0026gt; \u0026quot;Arizona\u0026quot;, \u0026quot;Arizona\u0026quot;, \u0026quot;Arizona\u0026quot;, \u0026quot;Arizona\u0026quot;, \u0026quot;Arizon… ## $ team_name \u0026lt;chr\u0026gt; \u0026quot;Cardinals\u0026quot;, \u0026quot;Cardinals\u0026quot;, \u0026quot;Cardinals\u0026quot;, \u0026quot;Cardinals\u0026quot;,… ## $ year \u0026lt;dbl\u0026gt; 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 200… ## $ total \u0026lt;dbl\u0026gt; 893926, 893926, 893926, 893926, 893926, 893926, 893… ## $ home \u0026lt;dbl\u0026gt; 387475, 387475, 387475, 387475, 387475, 387475, 387… ## $ away \u0026lt;dbl\u0026gt; 506451, 506451, 506451, 506451, 506451, 506451, 506… ## $ week \u0026lt;dbl\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, … ## $ weekly_attendance \u0026lt;dbl\u0026gt; 77434, 66009, NA, 71801, 66985, 44296, 38293, 62981…  standings \u0026lt;- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-04/standings.csv', col_types = cols()) glimpse(standings)  ## Observations: 638 ## Variables: 15 ## $ team \u0026lt;chr\u0026gt; \u0026quot;Miami\u0026quot;, \u0026quot;Indianapolis\u0026quot;, \u0026quot;New York\u0026quot;, \u0026quot;Buffalo\u0026quot;, … ## $ team_name \u0026lt;chr\u0026gt; \u0026quot;Dolphins\u0026quot;, \u0026quot;Colts\u0026quot;, \u0026quot;Jets\u0026quot;, \u0026quot;Bills\u0026quot;, \u0026quot;Patriots\u0026quot;… ## $ year \u0026lt;dbl\u0026gt; 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, … ## $ wins \u0026lt;dbl\u0026gt; 11, 10, 9, 8, 5, 13, 12, 9, 7, 4, 3, 12, 11, 7, … ## $ loss \u0026lt;dbl\u0026gt; 5, 6, 7, 8, 11, 3, 4, 7, 9, 12, 13, 4, 5, 9, 10,… ## $ points_for \u0026lt;dbl\u0026gt; 323, 429, 321, 315, 276, 346, 333, 321, 367, 185… ## $ points_against \u0026lt;dbl\u0026gt; 226, 326, 321, 350, 338, 191, 165, 255, 327, 359… ## $ points_differential \u0026lt;dbl\u0026gt; 97, 103, 0, -35, -62, 155, 168, 66, 40, -174, -2… ## $ margin_of_victory \u0026lt;dbl\u0026gt; 6.1, 6.4, 0.0, -2.2, -3.9, 9.7, 10.5, 4.1, 2.5, … ## $ strength_of_schedule \u0026lt;dbl\u0026gt; 1.0, 1.5, 3.5, 2.2, 1.4, -1.3, -2.5, -0.2, -1.4,… ## $ simple_rating \u0026lt;dbl\u0026gt; 7.1, 7.9, 3.5, 0.0, -2.5, 8.3, 8.0, 3.9, 1.1, -1… ## $ offensive_ranking \u0026lt;dbl\u0026gt; 0.0, 7.1, 1.4, 0.5, -2.7, 1.5, 0.0, 0.6, 3.2, -8… ## $ defensive_ranking \u0026lt;dbl\u0026gt; 7.1, 0.8, 2.2, -0.5, 0.2, 6.8, 8.0, 3.3, -2.1, -… ## $ playoffs \u0026lt;chr\u0026gt; \u0026quot;Playoffs\u0026quot;, \u0026quot;Playoffs\u0026quot;, \u0026quot;No Playoffs\u0026quot;, \u0026quot;No Playo… ## $ sb_winner \u0026lt;chr\u0026gt; \u0026quot;No Superbowl\u0026quot;, \u0026quot;No Superbowl\u0026quot;, \u0026quot;No Superbowl\u0026quot;, …  The question: to super bowl winners have harder schedules? I am curious if teams that win the super bowl have an easier or harder schedule than the other teams that make it to the playoffs. The strength_of_schedule variable provides a simple way to test this.\nThe only data manipulation we need to do is combine playoffs and sb_winner:\nstandings \u0026lt;- standings %\u0026gt;% mutate(final_position = if_else(sb_winner == \u0026quot;Won Superbowl\u0026quot;, sb_winner, playoffs))  Summarize data standing_summary \u0026lt;- standings %\u0026gt;% group_by(final_position) %\u0026gt;% summarize(less_zero = sum(strength_of_schedule \u0026lt; 0), total = n(), percent_less_zero = less_zero / total, median_strength = median(strength_of_schedule) ) standing_summary  ## # A tibble: 3 x 5 ## final_position less_zero total percent_less_zero median_strength ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 No Playoffs 170 398 0.427 0.2 ## 2 Playoffs 132 220 0.6 -0.5 ## 3 Won Superbowl 8 20 0.4 0.2  It looks like most teams that make it to the playoffs have an easier schedule (60% of them hace an average opponent rating less than zero) than those that win the super bowl (only 40% have average opponent rating less than zero). Teams that don\u0026rsquo;t make the playoffs also seem to have more difficult schedule.\nTest the difference in schedule strength The Kruskal-Wallis is suitable for multiple rank-based comparisons of groups:\nstandings %\u0026gt;% kruskal.test(strength_of_schedule ~ final_position, data = .)  ## ## Kruskal-Wallis rank sum test ## ## data: strength_of_schedule by final_position ## Kruskal-Wallis chi-squared = 27.31, df = 2, p-value = 1.174e-06  But sometimes, doing pairwise Wilcox tests can be more interpretable.\nstandings %\u0026gt;% filter(final_position != \u0026quot;Won Superbowl\u0026quot;) %\u0026gt;% wilcox.test(strength_of_schedule ~ final_position, data = .)  ## ## Wilcoxon rank sum test with continuity correction ## ## data: strength_of_schedule by final_position ## W = 54732, p-value = 2.549e-07 ## alternative hypothesis: true location shift is not equal to 0  standings %\u0026gt;% filter(final_position != \u0026quot;No Playoffs\u0026quot;) %\u0026gt;% wilcox.test(strength_of_schedule ~ final_position, data = .)  ## ## Wilcoxon rank sum test with continuity correction ## ## data: strength_of_schedule by final_position ## W = 1599, p-value = 0.04333 ## alternative hypothesis: true location shift is not equal to 0  Plot Manually specify some colors (taken from the fun wesanderson package)\nfinal_position_pal = c( \u0026quot;No Playoffs\u0026quot; = \u0026quot;#F2AD00\u0026quot;, \u0026quot;Playoffs\u0026quot; = \u0026quot;#00A08A\u0026quot;, \u0026quot;Won Superbowl\u0026quot; = \u0026quot;#FF0000\u0026quot; )  We will use the features of the great new ggtext package to color text in the subtitle of the plot, obviating the need for a figure legend.\nlibrary(ggtext) standings %\u0026gt;% ggplot(aes(x = final_position, y = strength_of_schedule, fill = final_position)) + geom_hline(yintercept = 0, lwd = 0.5, lty = 2, color = 'grey 50') + geom_boxplot() + #geom_jitter(width = 0.25) + geom_text(data = standing_summary, inherit.aes = FALSE, nudge_y = 0.22, mapping = aes(x = final_position, y = median_strength, label = median_strength)) + scale_fill_manual(values = final_position_pal, guide = 'none' ) + theme_minimal() + theme(axis.title = element_blank(), axis.text.x = element_blank(), panel.grid.minor = element_blank(), panel.grid.major.x = element_blank(), plot.title = element_textbox(), plot.subtitle = element_markdown(linewidth = 20) ) + labs(title = \u0026quot;**No Easy Road to Super Bowl Victory**\u0026quot;, subtitle = \u0026quot;Since 2000, NFL \u0026lt;b style='color:#F2AD00'\u0026gt;teams that miss the playoffs\u0026lt;/b\u0026gt; have a harder schedule (an average opponent rating greater than the dashed line at zero) than \u0026lt;b style='color:#00A08A'\u0026gt;teams that make it to the playoffs\u0026lt;/b\u0026gt;. A \u0026lt;b style='color:#FF0000'\u0026gt;Super Bowl winner's\u0026lt;/b\u0026gt; schedule is much tougher by comparison.\u0026quot; ) + ggsave(filename = 'featured.png', width = 7, height = 7)  Bonus: Color by Team Name How does it look to plot individual points for each team, coloring them accoring to their team colors (thanks to the teamcolors package)?\nteam_fill = teamcolors::league_pal('nfl', which = 2) team_color = teamcolors::league_pal('nfl', which = 1) ## Use just team name, not the home city (which changes for a couple teams) names(team_fill) \u0026lt;- str_remove(names(team_fill), \u0026quot;^.* \u0026quot;) names(team_color) \u0026lt;- str_remove(names(team_color), \u0026quot;^.* \u0026quot;) standings %\u0026gt;% ggplot(aes(x = final_position, y = strength_of_schedule, fill = team_name, color = team_name)) + geom_jitter(width = 0.4, pch = 23, size = 3) + scale_fill_manual(values = team_fill, guide = 'none' ) + scale_color_manual(values = team_color, guide = 'none' ) + theme_minimal() + theme(axis.title = element_blank(), panel.grid.minor = element_blank(), panel.grid.major.x = element_blank(), plot.title = element_textbox(), plot.subtitle = element_markdown(linewidth = 20) )  Ugly. Too many of the teams have colors that are close to one another.\nBonus: What is the bump in attendance the year after winning a superbowl? Making use of the lag() function, if you account for the fact that each team has a different \u0026ldquo;baseline\u0026rdquo; of attendance, it looks like the year after a superbowl win, attendence to away games may go up a bit. Home games and total attendance doesn\u0026rsquo;t really change though.\nattendance %\u0026gt;% select(team, team_name, year, total, home, away) %\u0026gt;% distinct() %\u0026gt;% group_by(team) %\u0026gt;% ## adjust attendance on a per-team basis to account for a difference baseline for each team mutate_at(vars(total, home, away), .funs = ~scale(., scale = FALSE) ) %\u0026gt;% ungroup() %\u0026gt;% full_join(standings) %\u0026gt;% group_by(team) %\u0026gt;% mutate_all(.funs = list(last_year = ~lag(.))) %\u0026gt;% filter(sb_winner_last_year == \u0026quot;Won Superbowl\u0026quot;) %\u0026gt;% filter(!is.na(sb_winner_last_year)) %\u0026gt;% ungroup() %\u0026gt;% arrange(team, year) %\u0026gt;% gather(attendance_the_year_after_winning_superbowl, value, total, total_last_year, home, home_last_year, away, away_last_year) %\u0026gt;% ggplot(aes(x = attendance_the_year_after_winning_superbowl, y = value)) + geom_boxplot() + ggpubr::stat_compare_means() + theme_minimal()  ## Joining, by = c(\u0026quot;team\u0026quot;, \u0026quot;team_name\u0026quot;, \u0026quot;year\u0026quot;) ## `mutate_all()` ignored the following grouping variables: ## Column `team` ## Use `mutate_at(df, vars(-group_cols()), myoperation)` to silence the message.  ","date":1580774400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580774400,"objectID":"4c9f34647c8762a229a04e3a13ab2a1d","permalink":"/post/2020-02-04-tt-football/","publishdate":"2020-02-04T00:00:00Z","relpermalink":"/post/2020-02-04-tt-football/","section":"post","summary":"Dip into the new ggttext package to get some rich text formatting in a plot\u0026rsquo;s title. Also: sports.\n","tags":["R","ggtext"],"title":"Tidy Tuesday: NFL Stadium Attendance","type":"post"},{"authors":["Tanner Koomar"],"categories":null,"content":"","date":1579219200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579219200,"objectID":"2d0d10e6b344fcbbc2a8cf652a64f9c7","permalink":"/publication/2020-language-review-paper/","publishdate":"2020-01-17T00:00:00Z","relpermalink":"/publication/2020-language-review-paper/","section":"publication","summary":"This review examines the genetic and phenotypic overlaps of language impairments and neuropsychatric conditions.","tags":["autism","bipolar disorder","major depression","schizophrenia","adhd","language genetics"],"title":"Genetic Intersections of Language and Neuropsychiatric Conditions","type":"publication"},{"authors":["Tanner Koomar"],"categories":null,"content":"","date":1570665600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570665600,"objectID":"4a20089737756f76b7f43c7ddbe31e0a","permalink":"/publication/2019-miccai-paper/","publishdate":"2019-10-10T00:00:00Z","relpermalink":"/publication/2019-miccai-paper/","section":"publication","summary":"Placed 2nd in an machine learning competition to predict fluid intellegence from structural brain MRI, sponsored by the Medical Image Computing and Computer Assisted Intervention conference.","tags":["MRI","Machie Learning","ABCD"],"title":"Ensemble Modeling of Neurocognitive Performance Using MRI-Derived Brain Structure Volumes","type":"publication"},{"authors":null,"categories":["tidytuesday"],"content":"Animated GIFs showing changes to funding of university research, broken down by speciality.\nIf you take a look at this table raw, it really is quite the mess. It is kind of hard to imagine data that is less tidy:\nlibrary(tidyverse) library(gganimate) library(showtext) ## for google fonts font_add_google(\u0026quot;Dosis\u0026quot;) font_add_google(\u0026quot;Comfortaa\u0026quot;) showtext_auto() download.file(\u0026quot;https://www.aaas.org/sites/default/files/2018-11/UniDisc1.xlsx\u0026quot;, \u0026quot;2019-05-08_UniDisc1.xlsx\u0026quot;) readxl::read_excel(\u0026quot;2019-05-08_UniDisc1.xlsx\u0026quot;)  ## # A tibble: 103 x 13 ## `University R\u0026amp;D… X__1 X__2 X__3 X__4 X__5 X__6 X__7 X__8 X__9 ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (budget authori… NA NA NA NA NA NA NA NA NA ## 2 \u0026lt;NA\u0026gt; 2007 2008 2009 2010 2011 2012 2013 2014 2015 ## 3 Computer Scienc… 1696. 1709. 1837 1864. 1943. 1996. 2228. 2040. 2051. ## 4 \u0026lt;NA\u0026gt; NA NA NA NA NA NA NA NA NA ## 5 Environmental S… NA NA NA NA NA NA NA NA NA ## 6 Atmospheric Sci… 529. 491. 478. 488. 537. 522. 531. 531. 600. ## 7 Earth Sciences 1080. 1104. 1170. 1233. 1274. 1280. 1253. 1226. 1164. ## 8 Oceanography 1176. 1220. 1237. 1163. 1170. 1123 1132. 1133. 1098. ## 9 Other Environme… 393. 434. 470 520. 535. 550. 524. 524. 533. ## 10 Total Environme… 3178. 3250. 3356. 3404 3516. 3475. 3441. 3414. 3394. ## # ... with 93 more rows, and 3 more variables: X__10 \u0026lt;dbl\u0026gt;, X__11 \u0026lt;dbl\u0026gt;, ## # X__12 \u0026lt;chr\u0026gt;  We have a couple header rows and then disciplines, followed by several sub-disciplines (or none). In Excel, this looks rather inteligible because of bold formating, etc. We have none of that here and have to get a litle creative to separate and assign disciplines to sub-disciplines.\nThe main pattern we have here is that every discipline row is preceded by an NA value. Combining dplyr::lag(), which gets the last value in a vector with zoo::locf(), which replaces NA\u0026rsquo;s with the most recent non-missing value.\ntot_dat \u0026lt;- readxl::read_excel(\u0026quot;2019-05-08_UniDisc1.xlsx\u0026quot;, skip = 2, ## header junk n_max = 47 ## 2nd table appears after here ) %\u0026gt;% mutate(discipline = case_when( is.na(lag(X__1)) ~ X__1)) %\u0026gt;% ## get the category columns select(X__1, discipline, everything()) %T\u0026gt;% ## these two lines are just for printing out the {print(head(.))} %\u0026gt;% ## intermediary results mutate(discipline = zoo::na.locf(discipline), funding_source = \u0026quot;total\u0026quot;) %T\u0026gt;% {print(head(.))} %\u0026gt;% filter(!is.na((X__1)), !is.na(`2007`), !str_detect(X__1, \u0026quot;Total\u0026quot;) ) %\u0026gt;% rename('sub_discipline' = 'X__1') %T\u0026gt;% {print(head(.))} %\u0026gt;% select(-`'07 - '17`) %\u0026gt;% gather(`2007`:`2017`, key = year, value = budget) %T\u0026gt;% {print(head(.))} %\u0026gt;% mutate(budget = budget*1e6)  ## # A tibble: 6 x 14 ## X__1 discipline `2007` `2008` `2009` `2010` `2011` `2012` `2013` `2014` ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Comp… Computer … 1696. 1709. 1837 1864. 1943. 1996. 2228. 2040. ## 2 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; NA NA NA NA NA NA NA NA ## 3 Envi… Environme… NA NA NA NA NA NA NA NA ## 4 Atmo… \u0026lt;NA\u0026gt; 529. 491. 478. 488. 537. 522. 531. 531. ## 5 Eart… \u0026lt;NA\u0026gt; 1080. 1104. 1170. 1233. 1274. 1280. 1253. 1226. ## 6 Ocea… \u0026lt;NA\u0026gt; 1176. 1220. 1237. 1163. 1170. 1123 1132. 1133. ## # ... with 4 more variables: `2015` \u0026lt;dbl\u0026gt;, `2016` \u0026lt;dbl\u0026gt;, `2017` \u0026lt;dbl\u0026gt;, ## # `'07 - '17` \u0026lt;dbl\u0026gt; ## # A tibble: 6 x 15 ## X__1 discipline `2007` `2008` `2009` `2010` `2011` `2012` `2013` `2014` ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Comp… Computer … 1696. 1709. 1837 1864. 1943. 1996. 2228. 2040. ## 2 \u0026lt;NA\u0026gt; Computer … NA NA NA NA NA NA NA NA ## 3 Envi… Environme… NA NA NA NA NA NA NA NA ## 4 Atmo… Environme… 529. 491. 478. 488. 537. 522. 531. 531. ## 5 Eart… Environme… 1080. 1104. 1170. 1233. 1274. 1280. 1253. 1226. ## 6 Ocea… Environme… 1176. 1220. 1237. 1163. 1170. 1123 1132. 1133. ## # ... with 5 more variables: `2015` \u0026lt;dbl\u0026gt;, `2016` \u0026lt;dbl\u0026gt;, `2017` \u0026lt;dbl\u0026gt;, ## # `'07 - '17` \u0026lt;dbl\u0026gt;, funding_source \u0026lt;chr\u0026gt; ## # A tibble: 6 x 15 ## sub_discipline discipline `2007` `2008` `2009` `2010` `2011` `2012` ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Computer Scie… Computer … 1696. 1709. 1837 1864. 1943. 1996. ## 2 Atmospheric S… Environme… 529. 491. 478. 488. 537. 522. ## 3 Earth Sciences Environme… 1080. 1104. 1170. 1233. 1274. 1280. ## 4 Oceanography Environme… 1176. 1220. 1237. 1163. 1170. 1123 ## 5 Other Environ… Environme… 393. 434. 470 520. 535. 550. ## 6 Agricultural … Life Scie… 3453 3478. 3507. 3426 3476. 3614 ## # ... with 7 more variables: `2013` \u0026lt;dbl\u0026gt;, `2014` \u0026lt;dbl\u0026gt;, `2015` \u0026lt;dbl\u0026gt;, ## # `2016` \u0026lt;dbl\u0026gt;, `2017` \u0026lt;dbl\u0026gt;, `'07 - '17` \u0026lt;dbl\u0026gt;, funding_source \u0026lt;chr\u0026gt; ## # A tibble: 6 x 5 ## sub_discipline discipline funding_source year budget ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Computer Sciences Computer Sciences total 2007 1696. ## 2 Atmospheric Sciences Environmental Scie… total 2007 529. ## 3 Earth Sciences Environmental Scie… total 2007 1080. ## 4 Oceanography Environmental Scie… total 2007 1176. ## 5 Other Environmental Scie… Environmental Scie… total 2007 393. ## 6 Agricultural Sciences Life Sciences total 2007 3453  That looks much tidyr! Let\u0026rsquo;s do the same with the other table, a little bit more efficiently:\ntry( readxl::read_excel(\u0026quot;2019-05-08_UniDisc1.xlsx\u0026quot;, skip = 53, n_max = 47 ) %\u0026gt;% mutate(discipline = case_when( is.na(lag(X__1)) ~ X__1), discipline = zoo::na.locf(discipline), funding_source = \u0026quot;federal\u0026quot; ) %\u0026gt;% select(X__1, discipline, everything()) %\u0026gt;% filter(!is.na((X__1)), !is.na(`2007`), !str_detect(X__1, \u0026quot;Total\u0026quot;) ) %\u0026gt;% rename('sub_discipline' = 'X__1') %\u0026gt;% select(-`'07 - '17`) %\u0026gt;% gather(`2007`:`2017`, key = year, value = budget) %\u0026gt;% mutate(budget = budget*1e6) )  OH NO! There is an empty row after the header that wasn\u0026rsquo;t in the other table, and it is throwing us off. Let\u0026rsquo;s just remov that pesky row and pretend this never happened.\nfed_dat \u0026lt;- readxl::read_excel(\u0026quot;2019-05-08_UniDisc1.xlsx\u0026quot;, skip = 53, n_max = 47 ) %\u0026gt;% filter(!row_number() == 1) %\u0026gt;% mutate(discipline = case_when( is.na(lag(X__1)) ~ X__1), discipline = zoo::na.locf(discipline), funding_source = \u0026quot;federal\u0026quot; ) %\u0026gt;% select(X__1, discipline, everything()) %\u0026gt;% filter(!is.na((X__1)), !is.na(`2007`), !str_detect(X__1, \u0026quot;Total\u0026quot;) ) %\u0026gt;% rename('sub_discipline' = 'X__1') %\u0026gt;% select(-`'07 - '17`) %\u0026gt;% gather(`2007`:`2017`, key = year, value = budget) %\u0026gt;% mutate(budget = budget*1e6)  Finally, lets combine this all into one big tibble\ndat \u0026lt;- bind_rows(fed_dat, tot_dat) %\u0026gt;% spread(funding_source, budget) %\u0026gt;% mutate(other = total-federal) %\u0026gt;% gather(funding_source, budget, federal, other) %\u0026gt;% mutate(year = as.numeric(year), budget = ifelse(funding_source=='federal', budget, -budget)) %\u0026gt;% arrange(discipline) %\u0026gt;% mutate( sub_discipline = factor(sub_discipline, ordered = T, levels = unique(sub_discipline)) )  A new theme theme_fnd \u0026lt;- function(base_size = 11, base_family = \u0026quot;Comfortaa\u0026quot;, base_line_size = base_size/22, base_rect_size = base_size/22) { theme_minimal(base_size = base_size, base_family = base_family, base_line_size = base_line_size, base_rect_size = base_rect_size) %+replace% theme(plot.background = element_rect(fill = '#e5d3ac'), panel.background = element_rect(fill = '#efe5c8', color = NA), panel.grid = element_line(color = '#640c14', size = 0.15)) + theme(plot.margin = margin(20,20,5,25), text = element_text(colour = '#640c14'), axis.text = element_text(colour = '#640c14'), axis.text.y = element_text(margin = margin(2,2,2,20)), axis.text.x.top = element_text(size = 11), axis.ticks.x.top = element_blank(), plot.title = element_text(family = \u0026quot;Dosis\u0026quot;, size = 18, face = 'bold'), plot.subtitle = element_text(family = \u0026quot;Dosis\u0026quot;, hjust = 1) ) }  plot_1 \u0026lt;- dat %\u0026gt;% filter( discipline != \u0026quot;Life Sciences\u0026quot;) %\u0026gt;% ggplot(aes(y = sub_discipline, color = funding_source)) + geom_segment(aes(x = 0, xend = budget, yend = sub_discipline, color = funding_source), size = 2.5) + geom_point(aes(x = budget, y = sub_discipline, fill = discipline), pch = 21, size = 8 , stroke = 0) + scale_fill_manual(values = c('Physical Sciences' = '#fcaf43', 'Computer Sciences' = '#e61e28', 'Environmental Sciences' = '#71a234', 'Social Sciences' = '#207e76', 'Psychology' = '#8dc642', 'Mathematical Sciences' = '#26bdb2', 'Engineering' = '#f26630', 'Other Sciences' = '#c21a24'), guide = guide_legend(title.position = 'top', title.hjust = 0.5, ncol = 2 )) + scale_color_manual(values = c('#5e2b15', '#9d4823'), guide = 'none') + scale_x_continuous(breaks = c(-1.5e9,0,2e9), minor_breaks = c(-.5e9,-1e9,.5e9,1e9,1.5e9), limits = c(-1.5e9,2e9), labels = c(\u0026quot;$1.5 Mil\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;$2 Mil\u0026quot;), position ='bottom', sec.axis = sec_axis(~., breaks = c(-0.75e9,1e9), labels = c(\u0026quot;all other funding\u0026quot;, \u0026quot;federal funding\u0026quot;) ) ) + labs(y = element_blank(), x = element_blank(), title = \u0026quot;funding for university research in {closest_state}\u0026quot;, subtitle = \u0026quot;(excluding life sciences)\u0026quot;, caption = \u0026quot;A #TidyTuesday Adventure by @TannerKoomar\\nsource: American Association for the Advancement of Science\u0026quot;) + theme_fnd() + theme(legend.position = 'bottom', legend.text = element_text(margin = margin(5,40,5,0)), panel.grid.major.y = element_blank()) + transition_states( year, transition_length = 2, state_length = 1 ) anim_save(animation = plot_1, filename = \u0026quot;final_plot_1.gif\u0026quot;, width = 700, height = 700)  plot_2 \u0026lt;- dat %\u0026gt;% filter( discipline == \u0026quot;Life Sciences\u0026quot;) %\u0026gt;% ggplot(aes(y = sub_discipline, color = funding_source)) + geom_segment(aes(x = 0, xend = budget, yend = sub_discipline, color = funding_source), size = 3) + geom_point(aes(x = budget, y = sub_discipline), pch = 21, size = 7 , stroke = 0, fill = '#71a234') + scale_color_manual(values = c('#5e2b15', '#9d4823'), guide = 'none') + scale_x_continuous(breaks = c(-12e9,0,16e9), minor_breaks = c(-4e9,-8e9,4e9,8e9), limits = c(-12e9,16e9), labels = c(\u0026quot;$12 Mil\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;$16 Mil\u0026quot;), position ='bottom', sec.axis = sec_axis(~., breaks = c(-6e9,8e9), labels = c(\u0026quot;all other funding\u0026quot;, \u0026quot;federal funding\u0026quot;) ) ) + labs(y = element_blank(), x = element_blank(), title = \u0026quot;funding for university research in {closest_state}\u0026quot;, caption = \u0026quot;A #TidyTuesday Adventure by @TannerKoomar\\nsource: American Association for the Advancement of Science\u0026quot;) + theme_fnd() + theme(legend.position = 'bottom', panel.grid.major.y = element_blank()) + transition_states( year, transition_length = 2, state_length = 1 ) anim_save(animation = plot_2, filename = \u0026quot;final_plot_2.gif\u0026quot;, width = 700, height = 350)  ","date":1557273600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557273600,"objectID":"35e5ac8374ce37090c63b8b1c041866e","permalink":"/post/2019-05-08-tt-uni-funding/","publishdate":"2019-05-08T00:00:00Z","relpermalink":"/post/2019-05-08-tt-uni-funding/","section":"post","summary":"Animated GIFs showing changes to funding of university research, broken down by speciality.\n","tags":["R","gif"],"title":"Tidy Tuesday: University Research Funding","type":"post"},{"authors":null,"categories":["tidytuesday"],"content":"A look at housing price trends over the last century with a compound infographic.\n  format data   A new theme   violin plot   statebin maps   line plots   map key   texts   title   narrative   footer     Asemble   The final Plot   library(tidyverse) library(statebins) library(cowplot) library(magick) library(showtext) ## for google fonts font_add_google(\u0026quot;Staatliches\u0026quot;) font_add_google(\u0026quot;Oswald\u0026quot;) font_add_google(\u0026quot;Montserrat\u0026quot;, regular.wt = 300, bold.wt = 500) showtext_auto() ## read in data hpi_dat \u0026lt;- read_csv(\u0026quot;https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-02-05/state_hpi.csvhttps://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-02-05/state_hpi.csv\u0026quot;)  ## Parsed with column specification: ## cols( ## year = col_integer(), ## month = col_integer(), ## state = col_character(), ## price_index = col_double(), ## us_avg = col_double() ## )  format data hpi_dat \u0026lt;- hpi_dat %\u0026gt;% mutate(years = cut(year, breaks = c(1975, 1980, 1985, 1990, 1995, 2000, 2005, 2010, 2015, 2018), labels = c(1975, 1980, 1985, 1990, 1995, 2000, 2005, 2010, 2015), include.lowest = TRUE ) ) %\u0026gt;% group_by(years) %\u0026gt;% mutate( price_ratio = price_index/us_avg, price_sd = sd(price_index/us_avg) ) %\u0026gt;% ungroup() %\u0026gt;% left_join(tibble(state = state.abb, region = as.character(state.division))) %\u0026gt;% mutate(region = replace_na(region, \u0026quot;Washington DC\u0026quot;))  ## Joining, by = \u0026quot;state\u0026quot;  A new theme theme_house\u0026lt;- function(base_size = 11, base_family = \u0026quot;Oswald\u0026quot;, base_line_size = base_size/22, base_rect_size = base_size/22) { theme_minimal(base_size = base_size, base_family = base_family, base_line_size = base_line_size, base_rect_size = base_rect_size) %+replace% theme(axis.title = element_text(face = 'bold', hjust = 0, size = 14), strip.text = element_text(hjust = 1)) }  violin plot violin \u0026lt;- hpi_dat %\u0026gt;% ggplot(aes(x = years, y = (price_ratio), fill = price_sd)) + geom_hline(yintercept = 1 , lty = 2) + geom_violin(color = NA, alpha = 0.85) + scale_fill_gradientn(colors = c(\u0026quot;#F98400\u0026quot;,\u0026quot;#ECCBAE\u0026quot;), name = 'standard deviation of home prices') + labs(x = \u0026quot;5 year period\u0026quot;, y = \u0026quot;HPI relative to national average\u0026quot; ) + guides(fill = guide_colorbar(title.position = \u0026quot;top\u0026quot;, title.hjust = 0.5, label.position = 'bottom', barwidth = 15, barheight = .5) ) + scale_y_continuous(trans = 'log2', breaks = c(1/2, 1, 2), labels = c(\u0026quot;1/2x\u0026quot;, \u0026quot;1x\u0026quot;, \u0026quot;2x\u0026quot;), limits = c(1/2,2)) + #scale_fill_viridis_c(direction = -1, option = \u0026quot;E\u0026quot;) + theme_house() + theme(legend.direction = 'horizontal', legend.justification = c(.5, 0), legend.position = c(0.5, 0.78) ) violin  ## Warning: Removed 1 rows containing non-finite values (stat_ydensity).  statebin maps bin_maps \u0026lt;- hpi_dat %\u0026gt;% filter(years %in% c(1975, 1995, 2015)) %\u0026gt;% ggplot(aes(state = state, fill = cut(log2(price_ratio), breaks = c(-Inf, -.625, -.375, -.125, .125, .375, .625, Inf), include.lowest = TRUE, labels = c(\u0026quot;-1\u0026quot;, \u0026quot;-1/2\u0026quot;, \u0026quot;-1/4\u0026quot;, \u0026quot;0\u0026quot;, \u0026quot;1/4\u0026quot;, \u0026quot;1/2\u0026quot;, \u0026quot;1\u0026quot;) ) ) ) + geom_statebins(border_size = 0, dark_lbl = NA, light_lbl = NA) + facet_wrap(~years, nrow = 3) + coord_equal() + guides(fill = guide_legend(title.position = 'top', title.hjust = 0.5, label.position = 'bottom', direction = 'horizontal', nrow = 1, keyheight = .75, keywidth = c(2, 1, 1, 2, 1, 1, 2) ) ) + scale_fill_manual(values = colorRampPalette(c(\u0026quot;#FF0000\u0026quot;, \u0026quot;#fbf4ee\u0026quot;, \u0026quot;#00A08A\u0026quot;))(7), name = \u0026quot;HPI relative to national average\u0026quot;, labels = c(\u0026quot;1/2x\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;1x\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot; 2x\u0026quot;)) + ggtitle(\u0026quot;Home Prices in Flyover\\nCountry Can't Keep Up\u0026quot;) + theme_void() + theme(plot.title=element_text(family = \u0026quot;Oswald\u0026quot;, size=20, hjust=1, lineheight = 0.85), plot.margin = margin(0,10,0,10), strip.text = element_text(family = \u0026quot;Oswald\u0026quot;, size = 24, hjust = 0), legend.position = 'top', legend.justification = 0.5, legend.direction = 'horizontal', legend.text = element_text(family = \u0026quot;Oswald\u0026quot;) ) bin_maps  line plots lines \u0026lt;- hpi_dat %\u0026gt;% group_by(year, region) %\u0026gt;% ggplot(aes(x = year, y = price_ratio, color = region, group = region)) + geom_hline(yintercept = 1, lty = 2, lwd = 0.25) + scale_y_continuous(trans = 'log2', breaks = c(1/2, 1, 2), labels = c(\u0026quot;1/2x\u0026quot;, \u0026quot;1x\u0026quot;, \u0026quot;2x\u0026quot;), limits = c(1/2,2)) + labs(y = \u0026quot;HPI relative to national average\u0026quot;) + geom_line(alpha = 0.85, size = 4, show.legend = FALSE) + facet_wrap(~region, ncol = 2) + scale_color_manual(values = c(\u0026quot;#FF0000\u0026quot;, \u0026quot;#00A08A\u0026quot;, \u0026quot;#F2AD00\u0026quot;, \u0026quot;#F98400\u0026quot;, \u0026quot;#5bd679\u0026quot;, \u0026quot;#ECCBAE\u0026quot;, \u0026quot;#046C9A\u0026quot;, \u0026quot;#000000\u0026quot;, \u0026quot;#ABDDDE\u0026quot;, \u0026quot;#D69C4E\u0026quot; )) + theme_house() + theme(axis.title = element_text(size = 22)) lines  ## Warning: Removed 1 rows containing missing values (geom_path).  map key bin_map_key \u0026lt;- hpi_dat %\u0026gt;% left_join(tibble(state = state.abb, region = state.division)) %\u0026gt;% ggplot(aes(state = state, fill = region)) + geom_statebins(border_size = 0, family = \u0026quot;Montserrat\u0026quot; ) + scale_fill_manual(values = c(\u0026quot;#FF0000\u0026quot;, \u0026quot;#00A08A\u0026quot;, \u0026quot;#F2AD00\u0026quot;, \u0026quot;#F98400\u0026quot;, \u0026quot;#5bd679\u0026quot;, \u0026quot;#ECCBAE\u0026quot;, \u0026quot;#046C9A\u0026quot;, \u0026quot;#000000\u0026quot;, \u0026quot;#ABDDDE\u0026quot;, \u0026quot;#D69C4E\u0026quot;)) + coord_equal() + ggtitle(\u0026quot;Regions of the United States\u0026quot;) + theme_void() + theme(plot.title=element_text(family = \u0026quot;Oswald\u0026quot;, size=20, hjust=0), plot.margin = margin(10,10,10,10), legend.position = 'none' )  ## Joining, by = c(\u0026quot;state\u0026quot;, \u0026quot;region\u0026quot;) ## Warning: Column `region` joining character vector and factor, coercing into ## character vector  bin_map_key  texts title header \u0026lt;- ggplot() + annotate(geom = \u0026quot;text\u0026quot;, y = -0.1, x = 0.5, size = 10, family = \u0026quot;Staatliches\u0026quot;, color = 'white', alpha = 1, lineheight = 0.7, hjust = 1, label=\u0026quot;HOW THE HOUSING\\nPRICE INDEX\u0026quot; ) + annotate(geom = \u0026quot;text\u0026quot;, y = -0.1, x = .79, size = 12, family = \u0026quot;Staatliches\u0026quot;, color = 'white', alpha = 1, lineheight = 0.9, hjust = 0, label=\u0026quot;FLIPPED\u0026quot; ) + ylim(-2,2) + xlim(-2,2) + theme_void() + theme( plot.background = element_rect(color = \u0026quot;white\u0026quot;, fill = \u0026quot;transparent\u0026quot;, size = 5) ) ggdraw() + draw_image(\u0026quot;house.png\u0026quot;) + draw_plot(header)  narrative narr \u0026lt;- ggplot() + annotate(geom = \u0026quot;text\u0026quot;, y = 0, x= -2, size = 5.5, family = \u0026quot;Montserrat\u0026quot;, color = 'black', alpha = 0.75, lineheight = 0.9, hjust = 0, label=str_wrap(\u0026quot;In the 1970's, many individual states had average home prices (HPI) above the national average. The spread of house prices narrowed, until the mid 1990's. After this inflection point, house prices again grew more extreme. Less populous states drive this trend, with home prices in these regions going from above average to below it.\u0026quot;, 30) ) + ylim(-2,2) + xlim(-2,2) + theme_void() + theme( plot.background = element_rect(color = \u0026quot;white\u0026quot;, fill = '#e5e5ff', size = 5) ) narr  footer foot \u0026lt;- ggplot() + annotate(geom = \u0026quot;text\u0026quot;, y = 0, x= 0, size = 3, family = \u0026quot;Montserrat\u0026quot;, color = 'black', alpha = 0.5, hjust = 0.5, label= \u0026quot;◊ A #TidyTuesday adventure by @TannerKoomar ◊ Data from Freddie Mac ◊ Photo from pexels.com ◊\u0026quot; ) + ylim(-2,2) + xlim(-2,2) + theme_void() + theme( plot.background = element_rect(color = \u0026quot;white\u0026quot;, fill = '#e5e5ff', size = 3) ) foot  Asemble let\u0026rsquo;s try cowplot this time\nfinal_plot \u0026lt;- plot_grid( (ggdraw() + draw_image(\u0026quot;house.png\u0026quot;) + draw_plot(header)), plot_grid(violin, narr, rel_widths = c(5,3) ), plot_grid( plot_grid(bin_maps + theme(plot.background = element_rect(fill = alpha('#e5e5ff', 0.25), color = 'white', size = 2) ), bin_map_key, ncol = 1, rel_heights = c(3,1) ), lines, rel_widths = c(3, 5) ), foot, ncol = 1, rel_heights = c(1, 2, 6, 0.15) ) png(\u0026quot;final_plot.png\u0026quot;, width = 1000, height = 2000, res = 144, bg = \u0026quot;white\u0026quot;) final_plot dev.off()  ## png ## 2  The final Plot ","date":1555804800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555804800,"objectID":"59c4d13ada28f84091e48266c2019218","permalink":"/post/2019-04-21-tt-housing-prices/","publishdate":"2019-04-21T00:00:00Z","relpermalink":"/post/2019-04-21-tt-housing-prices/","section":"post","summary":"A look at housing price trends over the last century with a compound infographic.\n","tags":["R","map","gridExtra"],"title":"Tidy Tuesday: How The Housing Price Index Flipped","type":"post"},{"authors":null,"categories":["tidytuesday"],"content":"A simple animated gif map.\n  MAKE A MAP   Animate map     The final Plot   library(tidyverse)  ## ── Attaching packages ─────────────────── ## ✔ ggplot2 3.1.0 ✔ purrr 0.2.5 ## ✔ tibble 1.4.2 ✔ dplyr 0.7.7 ## ✔ tidyr 0.8.2 ✔ stringr 1.3.1 ## ✔ readr 1.1.1 ✔ forcats 0.3.0 ## ── Conflicts ─── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag()  require(transformr)  ## Loading required package: transformr  library(urbnmapr) library(gridExtra)  ## ## Attaching package: 'gridExtra' ## The following object is masked from 'package:dplyr': ## ## combine  library(gganimate) library(patchwork) source('https://raw.githubusercontent.com/tkoomar/ggplot2_themes/master/theme_black.R')  ## Loading required package: showtext ## Loading required package: sysfonts ## Loading required package: showtextdb  milk_state \u0026lt;- read_csv(\u0026quot;../data/2019/2019-01-29/state_milk_production.csv\u0026quot;)  ## Parsed with column specification: ## cols( ## region = col_character(), ## state = col_character(), ## year = col_integer(), ## milk_produced = col_double() ## ) ## Warning in rbind(names(probs), probs_f): number of columns of result is not ## a multiple of vector length (arg 1) ## Warning: 50 parsing failures. ## row # A tibble: 5 x 5 col row col expected actual file expected \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; actual 1 1501 year no trailing chara… e3 '../data/2019/2019-01-29/state_mil… file 2 1502 year no trailing chara… e3 '../data/2019/2019-01-29/state_mil… row 3 1503 year no trailing chara… e3 '../data/2019/2019-01-29/state_mil… col 4 1504 year no trailing chara… e3 '../data/2019/2019-01-29/state_mil… expected 5 1505 year no trailing chara… e3 '../data/2019/2019-01-29/state_mil… ## ... ................. ... ........................................................................... ........ ........................................................................... ...... ........................................................................... .... ........................................................................... ... ........................................................................... ... ........................................................................... ........ ........................................................................... ## See problems(...) for more details.  milk_state \u0026lt;- milk_state %\u0026gt;% rename('state_name' = 'state') data('states') milk_map \u0026lt;- left_join(milk_state, states)  ## Joining, by = \u0026quot;state_name\u0026quot;  MAKE A MAP map_plot \u0026lt;- milk_map %\u0026gt;% group_by(year) %\u0026gt;% mutate(milk_total = sum(milk_produced), milk_scaled = milk_produced/milk_total ) %\u0026gt;% ggplot(aes(x = long, y = lat, fill = milk_scaled, group = group)) + geom_polygon(size = 0.25, color = 'black') + coord_map(projection = \u0026quot;albers\u0026quot;, lat0 = 39, lat1 = 45) + scale_fill_viridis_c(option = \u0026quot;inferno\u0026quot;)+ #scale_fill_distiller(palette = 'PuBuGn', direction = 1) + theme_black() + theme(legend.position = 'none', axis.text = element_blank(), axis.ticks = element_blank(), axis.line = element_blank(), axis.title = element_blank(), panel.grid = element_blank()) + ggtitle(\u0026quot;portion of milk production by year\u0026quot;, \u0026quot;{closest_state}\u0026quot;)  Animate map map_anim \u0026lt;- map_plot + transition_states(states = year, transition_length = 5, state_length = 5, wrap = TRUE) anim_save(animation = map_anim, filename = \u0026quot;final_plot.gif\u0026quot;, width = 640 )  ## Warning in lapply(row_vars$states, as.integer): NAs introduced by coercion ## Warning in f(..., self = self): NAs introduced by coercion  The final Plot ","date":1551484800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551484800,"objectID":"9623b76533d67c6757a05e6994ed13bf","permalink":"/post/2019-03-02-tt-milk-gif/","publishdate":"2019-03-02T00:00:00Z","relpermalink":"/post/2019-03-02-tt-milk-gif/","section":"post","summary":"A simple animated gif map.\n","tags":["R","gif"],"title":"Tidy Tuesday: Milk Production","type":"post"},{"authors":null,"categories":["tidytuesday"],"content":"  make some new columns   Set lables of variables of interest   Main plot   Morning   afternoon   sidebar   footer     The final Plot   library(tidyverse)  ## ── Attaching packages ────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.1.0 ✔ purrr 0.2.5 ## ✔ tibble 1.4.2 ✔ dplyr 0.7.7 ## ✔ tidyr 0.8.2 ✔ stringr 1.3.1 ## ✔ readr 1.1.1 ✔ forcats 0.3.0 ## ── Conflicts ───────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag()  library(lubridate)  ## ## Attaching package: 'lubridate' ## The following object is masked from 'package:base': ## ## date  library(gridExtra)  ## ## Attaching package: 'gridExtra' ## The following object is masked from 'package:dplyr': ## ## combine  source(\u0026quot;https://raw.githubusercontent.com/tkoomar/ggplot2_themes/master/theme_cc.R\u0026quot;)  ## Loading required package: showtext ## Loading required package: sysfonts ## Loading required package: showtextdb  tidytuesday_tweets \u0026lt;- readRDS(\u0026quot;../data/2019/2019-01-01/tidytuesday_tweets.rds\u0026quot;) rstats_tweets \u0026lt;- readRDS(\u0026quot;../data/2019/2019-01-01/rstats_tweets.rds\u0026quot;) ## helper function for formatting correlation output slope_conf \u0026lt;- function(x, y){ res \u0026lt;- lm(y ~ x) conf \u0026lt;- confint(res, \u0026quot;x\u0026quot;, 0.95) paste0(\u0026quot;95% confidence interval: \u0026quot;, round(conf[1], 3), \u0026quot;-\u0026quot;, round(conf[2], 3)) }  make some new columns We want to get the day of the week, and claculate the number of hastags per tweet.\nrstats_tweets \u0026lt;-rstats_tweets %\u0026gt;% mutate(w_day = wday(created_at, label = TRUE), hour = hour(created_at)) %\u0026gt;% rowwise() %\u0026gt;% mutate(n_hash = length(hashtags))  Set lables of variables of interest dat \u0026lt;- rstats_tweets %\u0026gt;% mutate(\u0026quot;retweet per hastag enrichment\u0026quot; = log2(retweet_count/n_hash), \u0026quot;number of hastags\u0026quot; = n_hash, \u0026quot;number of retweets\u0026quot; = retweet_count ) %\u0026gt;% gather(key, value, \u0026quot;retweet per hastag enrichment\u0026quot;, \u0026quot;number of hastags\u0026quot;, \u0026quot;number of retweets\u0026quot;)  Main plot morning_col \u0026lt;- alpha(\u0026quot;#ffd92f\u0026quot;, 0.35) noon_col \u0026lt;- alpha(\u0026quot;#e5c494\u0026quot;, 0.4) p_week \u0026lt;- dat %\u0026gt;% ggplot(aes(x = hour, y = value, color = key)) + annotate('rect', size = 0, xmin = 5, xmax = 9, ymin = -1, ymax = 5, fill = morning_col) + annotate('rect', size = 0, xmin = 12, xmax = 20, ymin = -1, ymax = 5, fill = noon_col) + stat_smooth(alpha = 0.1, size = 1.5) + geom_hline(yintercept = 0, lty = 3) + scale_color_brewer(palette = \u0026quot;Set2\u0026quot;) + facet_wrap(~ w_day, nrow = 1) + coord_cartesian(ylim = c(-1,5)) + ylab(\u0026quot;\u0026quot;) + theme_cc(base_size = 12) + theme(legend.position = \u0026quot;bottom\u0026quot;, plot.title = element_text(size = 26)) + ggtitle(\u0026quot;#rstats aren't early morning grinders\u0026quot;, \u0026quot;the average number of retweets and hashtags per #rstats tweet, by day and time\u0026quot;) p_week  ## `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = \u0026quot;cs\u0026quot;)' ## Warning: Removed 243274 rows containing non-finite values (stat_smooth).  Morning p_morning \u0026lt;- dat %\u0026gt;% filter(hour \u0026gt;= 5 \u0026amp; hour \u0026lt;= 9 ) %\u0026gt;% filter(retweet_count \u0026lt; 500) %\u0026gt;% ## there are a couple big outliers here { ggplot(., aes(x = as.factor(n_hash), y = retweet_count)) + #geom_jitter(color = alpha(noon_col, 0.05)) + geom_boxplot(color = \u0026quot;#b3b3b3\u0026quot;, fill = morning_col, outlier.colour = alpha(\u0026quot;#b3b3b3\u0026quot;, 0.02)) + stat_smooth(method = \u0026quot;lm\u0026quot;, color = \u0026quot;#e78ac3\u0026quot;, size = 2, aes(x = (n_hash), y = retweet_count)) + coord_cartesian(xlim = c(0, 19.75 ), ylim = c(0, 19.75)) + ggtitle(slope_conf(.$n_hash, .$retweet_count)) + theme_cc(base_size = 12) + xlab(\u0026quot;number of hashtags\u0026quot;) + ylab(\u0026quot;number of retweets\u0026quot;) } p_morning  ### sidebar\nmorning_sidebar \u0026lt;- ggplot() + ylim(-2,2) + xlim(-2,2) + annotate(\u0026quot;text\u0026quot;, x = -2, y = 2, hjust = 0, vjust = 1, lineheight = 0.75, family = \u0026quot;Poppins\u0026quot;, size = 5, color = \u0026quot;grey50\u0026quot;, label = str_wrap(string = \u0026quot;In general, more hashtags = more retweets. Early morning tweets usually contain more hashtags than tweets later in the day. Fewer people are on twitter at this time, so the apparent effectiveness of hashtags at provoking retweets is reduced. This begs the question: Why do people use more hashtags in the morning?\u0026quot;, width = 18) ) + theme_void() + theme( plot.background = element_rect( fill = morning_col,color = \u0026quot;white\u0026quot;, size = 2 ) ) morning_sidebar  afternoon p_noon \u0026lt;- dat %\u0026gt;% filter(hour \u0026gt;= 12 \u0026amp; hour \u0026lt;= 20 ) %\u0026gt;% filter(retweet_count \u0026lt; 500) %\u0026gt;% ## there are a couple big outliers here { ggplot(., aes(x = as.factor(n_hash), y = retweet_count)) + #geom_jitter(color = alpha(noon_col, 0.05)) + geom_boxplot(color = \u0026quot;#b3b3b3\u0026quot;, fill = noon_col, outlier.colour = alpha(\u0026quot;#b3b3b3\u0026quot;, 0.02)) + stat_smooth(method = \u0026quot;lm\u0026quot;, color = \u0026quot;#e78ac3\u0026quot;, size = 2, aes(x = (n_hash), y = retweet_count)) + coord_cartesian(xlim = c(0, 19.75 ), ylim = c(0, 19.75)) + ggtitle(slope_conf(.$n_hash, .$retweet_count)) + theme_cc(base_size = 12) + xlab(\u0026quot;number of hashtags\u0026quot;) + ylab(\u0026quot;number of retweets\u0026quot;) } p_noon  sidebar noon_sidebar \u0026lt;- ggplot() + ylim(-2,2) + xlim(-2,2) + annotate(\u0026quot;text\u0026quot;, x = -2, y = 2, hjust = 0, vjust = 1, lineheight = 0.75, family = \u0026quot;Poppins\u0026quot;, size = 5, color = \u0026quot;grey50\u0026quot;, label = str_wrap(string = \u0026quot;Hashtags used in the mid-afternoon, when most people are on twitter, are almost twice as effective at provoking retweets! Also, while most days see a single pronounced increase in tweets, Sunday afternoon sees two distinct bumps in #rstats tweets.\u0026quot;, width = 18) ) + theme_void() + theme( plot.background = element_rect( fill = noon_col, color = \u0026quot;white\u0026quot;, size = 2 ), plot.margin = unit(c(.01,.01,.01,.01), 'npc') ) noon_sidebar  footer footer \u0026lt;- ggplot() + ylim(-2,2) + xlim(-2,2) + annotate(\u0026quot;text\u0026quot;, x = -2, y = 2, hjust = 0, vjust = 1, lineheight = 0.75, family = \u0026quot;Poppins\u0026quot;, size = 2.5, color = \u0026quot;grey50\u0026quot;, label = paste0(\u0026quot;A #TidyTuesday adventure\\n\u0026quot;, \u0026quot;Data from rtweet.info\\n\u0026quot;, \u0026quot;Analysis @Tanner Koomar\\n\u0026quot;, \u0026quot;Design @Tanner Koomar\\n\u0026quot;, \u0026quot;https://github.com/tkoomar/\\ntidytuesday/blob/master/\\nwork/2019-01-01.md\u0026quot;) ) + theme_void() + theme( plot.background = element_rect( fill = alpha(\u0026quot;#b3b3b3\u0026quot;, 0.5), color = \u0026quot;white\u0026quot;, size = 2 ), plot.margin = unit(c(.01,.01,.01,.01), 'npc') ) footer  Assemble! #### legend\nplot_leg \u0026lt;- cowplot::get_legend(p_week + theme(legend.title = element_blank(), legend.justification = 'right')) plot_leg  ## TableGrob (5 x 5) \u0026quot;guide-box\u0026quot;: 2 grobs ## z cells name ## 99_e27293391d92b7a74a1c708851c8c43e 1 (3-3,3-3) guides ## 0 (2-4,2-4) legend.box.background ## grob ## 99_e27293391d92b7a74a1c708851c8c43e gtable[layout] ## zeroGrob[NULL]  png(\u0026quot;featured.png\u0026quot;, width = 1200, height = 900, res = 144, bg = \u0026quot;white\u0026quot;) grid.arrange( p_week + theme(legend.position = 'none'), morning_sidebar, p_morning + theme(axis.text.x = element_blank()), p_noon + theme(axis.text.x = element_blank()), noon_sidebar, footer, plot_leg, heights = c(.55,.15, .25,.25,.15), widths = c(.5, 1, 1, .5), layout_matrix = rbind(c(1,1,1,1), c(2,7,7,5), c(2,3,4,5), c(2,3,4,5), c(2,3,4,6) ) )  ## `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = \u0026quot;cs\u0026quot;)' ## Warning: Removed 243274 rows containing non-finite values (stat_smooth).  dev.off()  ## png ## 2  The final Plot ","date":1550016000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550016000,"objectID":"3174b91fcf4fb35d63ed4cbf380bd199","permalink":"/post/2019-02-13-tt-rstats-tweets/","publishdate":"2019-02-13T00:00:00Z","relpermalink":"/post/2019-02-13-tt-rstats-tweets/","section":"post","summary":"","tags":["R","twitter"],"title":"Tidy Tuesday: R Tweets","type":"post"},{"authors":null,"categories":["tidytuesday"],"content":"Some light web-scraping and natual language processing reveals how different parts of speech may hint at an author\u0026rsquo;s intent (and impact).\n  Tidy the text   infinitives   all verbs     some plots   scatter plots   tables     break vs build   topics / tags plot   time to (ha)rvest some posts!   sentiment plot   violin plot   legend     text boxes   header   definition sidebar   top sidebar   bottom sidebar   footer     stitch it together   The final Plot   Tidy the text following along with this: https://cran.r-project.org/web/packages/tidytext/vignettes/tidytext.html\ninfinitives dat_infin \u0026lt;- dat %\u0026gt;% unnest_tokens(infin, title, token = \u0026quot;ngrams\u0026quot;, n = 2) %\u0026gt;% filter(str_detect(pattern = \u0026quot;to \u0026quot;, string = infin)) %\u0026gt;% mutate(word = str_remove(infin, \u0026quot;to \u0026quot;)) %\u0026gt;% left_join(parts_of_speech) %\u0026gt;% mutate(word_stem = wordStem(word, \u0026quot;english\u0026quot;)) %\u0026gt;% filter(str_detect(pos, regex(\u0026quot;Verb\u0026quot;, ignore_case = F)), !duplicated(x1)) %\u0026gt;% group_by(word_stem) %\u0026gt;% mutate(n = n()) %\u0026gt;% group_by(word_stem, n) %\u0026gt;% summarize(mean_claps = mean(claps), sum_claps = sum(claps), infin = first(infin) )  ## Joining, by = \u0026quot;word\u0026quot;  all verbs dat_verb \u0026lt;- dat %\u0026gt;% unnest_tokens(word, title) %\u0026gt;% left_join(parts_of_speech) %\u0026gt;% filter(str_detect(pos, regex(\u0026quot;Verb\u0026quot;, ignore_case = F)), !duplicated(x1)) %\u0026gt;% mutate(word_stem = wordStem(word, \u0026quot;english\u0026quot;)) %\u0026gt;% group_by(word_stem) %\u0026gt;% mutate(n = n()) %\u0026gt;% group_by(word_stem, n) %\u0026gt;% summarize(mean_claps = mean(claps), sum_claps = sum(claps), word = first(word) )  ## Joining, by = \u0026quot;word\u0026quot;  some plots scatter plots plot_point_infin \u0026lt;- dat_infin %\u0026gt;% filter(n \u0026gt; 5) %\u0026gt;% ggplot(aes(x = n, y = mean_claps, color = case_when( mean_claps \u0026gt; 500 ~ \u0026quot;high impact infinitives\u0026quot;, n \u0026gt; 100 ~ \u0026quot;overused infinitives\u0026quot;, TRUE ~ \u0026quot;low impact infinitives\u0026quot; ), label = case_when( mean_claps \u0026gt; 500 | n \u0026gt; 100 ~ infin, mean_claps \u0026gt; 200 \u0026amp; n \u0026gt; 50 ~ infin, TRUE ~ \u0026quot;\u0026quot;) ) ) + scale_colour_manual(values = c(colors_merb[3], colors_merb[1], colors_merb[2]), guide = guide_legend(title = NULL, override.aes = list(size = 4)) )+ geom_point() + geom_vline(xintercept = 100, lwd = 2, lty = 2, alpha = 0.3, color = \u0026quot;grey90\u0026quot;) + geom_hline(yintercept = 500, lwd = 2, lty = 2, alpha = 0.3, color = \u0026quot;grey90\u0026quot;) + geom_text_repel(force = 15, show.legend = FALSE) + theme_merb() + xlab(\u0026quot;number of times used\u0026quot;) + ylab(\u0026quot;mean number of claps\u0026quot;) + theme( legend.text = element_text(size = 12), legend.box.just = \u0026quot;right\u0026quot; ) plot_point_infin  dat_verb %\u0026gt;% filter(n \u0026gt; 5) %\u0026gt;% ggplot(aes(x = n, y = mean_claps, color = case_when( mean_claps \u0026gt; 500 ~ \u0026quot;high_impact\u0026quot;, n \u0026gt; 100 ~ \u0026quot;overused\u0026quot;, TRUE ~ \u0026quot;misc\u0026quot; ), label = case_when( mean_claps \u0026gt; 500 | n \u0026gt; 100 ~ word, mean_claps \u0026gt; 200 \u0026amp; n \u0026gt; 50 ~ word, TRUE ~ \u0026quot;\u0026quot;))) + scale_colour_manual(values = c(colors_merb[3], colors_merb[1], colors_merb[2])) + geom_point() + geom_vline(xintercept = 100, lwd = 2, lty = 2, alpha = 0.3, color = \u0026quot;grey90\u0026quot;) + geom_hline(yintercept = 500, lwd = 2, lty = 2, alpha = 0.3, color = \u0026quot;grey90\u0026quot;) + geom_text_repel(force = 15) + theme_merb() + xlab(\u0026quot;number of times used\u0026quot;) + ylab(\u0026quot;mean number of claps\u0026quot;) + theme( legend.position = \u0026quot;none\u0026quot; )  tables gtable_theme \u0026lt;- ttheme_minimal( core = list(fontfamily = \u0026quot;Share Tech Mono\u0026quot;, bg_params = list(fill = c(\u0026quot;#414C3B\u0026quot;, \u0026quot;#191919\u0026quot;)), fg_params = list( col = matrix(c(\u0026quot;white\u0026quot;, colors_merb[2], colors_merb[3]), nrow = 10, ncol = 3, byrow = T), fontsize = 12 ) ), colhead = list( bg_params = list(fill = \u0026quot;#222220\u0026quot;), fg_params = list(col = \u0026quot;white\u0026quot;, fontsize = 12) ), rowhead = list(), default = list(), padding = unit(c(2, 3), \u0026quot;mm\u0026quot;) ) infin_list \u0026lt;- dat_infin %\u0026gt;% ungroup() %\u0026gt;% filter(n \u0026gt; 5) %\u0026gt;% arrange(desc(mean_claps)) %\u0026gt;% select(infin, n, mean_claps) %\u0026gt;% mutate(mean_claps = round(mean_claps)) %\u0026gt;% rename(\u0026quot;infinitive\u0026quot; = \u0026quot;infin\u0026quot;, \u0026quot;times used\u0026quot; = \u0026quot;n\u0026quot;, \u0026quot;mean claps\u0026quot; = \u0026quot;mean_claps\u0026quot;) %\u0026gt;% head(10) %\u0026gt;% tableGrob(rows = NULL, theme = gtable_theme ) verb_list \u0026lt;- dat_verb %\u0026gt;% ungroup() %\u0026gt;% filter(n \u0026gt; 5) %\u0026gt;% arrange(desc(mean_claps)) %\u0026gt;% select(word, n, mean_claps) %\u0026gt;% mutate(mean_claps = round(mean_claps)) %\u0026gt;% rename(\u0026quot;verb\u0026quot; = \u0026quot;word\u0026quot;, \u0026quot;times used\u0026quot; = \u0026quot;n\u0026quot;, \u0026quot;mean claps\u0026quot; = \u0026quot;mean_claps\u0026quot;) %\u0026gt;% head(10) %\u0026gt;% tableGrob(rows = NULL, theme = gtable_theme) plot(infin_list)  plot(verb_list)  break vs build dat_bb \u0026lt;- dat %\u0026gt;% unnest_tokens(infin, title, token = \u0026quot;ngrams\u0026quot;, n = 2, drop = FALSE) %\u0026gt;% filter(str_detect(pattern = \u0026quot;to \u0026quot;, string = infin)) %\u0026gt;% filter(infin %in% c(\u0026quot;to break\u0026quot;, \u0026quot;to disrupt\u0026quot;, \u0026quot;to destroy\u0026quot;, \u0026quot;to create\u0026quot;, \u0026quot;to make\u0026quot;, \u0026quot;to build\u0026quot;)) %\u0026gt;% mutate( type = case_when( infin %in% c(\u0026quot;to break\u0026quot;, \u0026quot;to disrupt\u0026quot;, \u0026quot;to destroy\u0026quot;) ~ \u0026quot;break\u0026quot;, TRUE ~ \u0026quot;build\u0026quot; ) )  topics / tags plot plot_topic \u0026lt;- dat_bb %\u0026gt;% gather(tag, tag_true, contains(\u0026quot;tag_\u0026quot;)) %\u0026gt;% mutate(tag = str_remove(tag, \u0026quot;tag_\u0026quot;)) %\u0026gt;% group_by(type, tag) %\u0026gt;% summarize( tag_prop = mean(tag_true), tag_sd = sd(tag_true), tag_se = tag_sd/sqrt(n()) ) %\u0026gt;% ggplot(aes( x = factor(tag) %\u0026gt;% reorder(tag_prop, FUN = mean), y = tag_prop, fill = type) ) + geom_col(position=\u0026quot;dodge\u0026quot;, stat=\u0026quot;identity\u0026quot;) + scale_fill_manual(values = c(pink, olive), labels = c(\u0026quot;posts about breaking\\nor disrupting\u0026quot;, \u0026quot;posts about building\\nor creating\u0026quot;), guide = guide_legend(title = NULL)) + geom_errorbar(aes(ymin = tag_prop - tag_se, ymax = tag_prop + tag_se), position = position_dodge(0.9), size = 0.3, width = 0.5, color = \u0026quot;white\u0026quot; ) + xlab(\u0026quot;tag on post\u0026quot;)+ ylab(\u0026quot;proportion with tag\u0026quot;) + theme_merb() + theme( axis.text.x = element_text(hjust = .75, angle = 10) )  ## Warning: Ignoring unknown parameters: stat  plot_topic  time to (ha)rvest some posts! read_post \u0026lt;- function(url){ tryCatch( read_html(url, options = \u0026quot;NOERROR\u0026quot;) %\u0026gt;% html_nodes(\u0026quot;.graf--p\u0026quot;) %\u0026gt;% html_text() %\u0026gt;% str_flatten(\u0026quot; \u0026quot;), error = function(e){NA}, warning = function(w){NA} ) } dat_bb \u0026lt;- dat_bb %\u0026gt;% mutate( full_text = map(url, read_post) ) dat_bb \u0026lt;- unnest(dat_bb) ## don't want to have to repeat that later, so save it now save(dat_bb, file = \u0026quot;2018-12-04_scraped_posts.RData\u0026quot;)  sentiment plot Not sure if stemming is needed here, given the way the sentiment dictionaries are constructed . . .\nsent \u0026lt;- get_sentiments(\u0026quot;loughran\u0026quot;) dat_sent \u0026lt;- dat_bb %\u0026gt;% filter(!is.na(full_text)) %\u0026gt;% unnest_tokens(word, full_text) %\u0026gt;% left_join(sent)  ## Joining, by = \u0026quot;word\u0026quot;  plot_sent \u0026lt;- dat_sent %\u0026gt;% group_by(x1, sentiment, type) %\u0026gt;% tally() %\u0026gt;% group_by(x1) %\u0026gt;% mutate( proportion = n / sum(n) ) %\u0026gt;% filter(!is.na(sentiment)) %\u0026gt;% group_by(type, sentiment) %\u0026gt;% summarise( median_prop = median(proportion), sd = sd(proportion), se = (1.2533 * sd) / sqrt(n())) %\u0026gt;% ggplot(aes(x = factor(sentiment) %\u0026gt;% reorder(median_prop), y = median_prop, fill = type)) + geom_col(position = \u0026quot;dodge\u0026quot;) + scale_fill_manual(values = c(pink, olive)) + geom_errorbar(aes(ymin = median_prop - se, ymax = median_prop + se), position = position_dodge(0.9), size = 0.3, width = 0.5, color = \u0026quot;white\u0026quot; ) + xlab(\u0026quot;sentiment\u0026quot;)+ ylab(\u0026quot;proportion of words in with sentiment\u0026quot;) + theme_merb() + theme(axis.text.x = element_text(angle = 15, hjust = .75)) plot_sent  violin plot plot_violin \u0026lt;- dat_bb %\u0026gt;% ggplot(aes(x = type, y= reading_time, fill = type, color = type)) + geom_violin(alpha = 0.85) + coord_cartesian(ylim = c(0,10)) + #geom_jitter(alpha = 0.3) + ## too busy stat_summary(fun.y = mean, fun.ymin = function(x){ quantile(x, probs = 0.25) }, fun.ymax = function(x){ quantile(x, probs = 0.75) }, size = 0.75, color = \u0026quot;black\u0026quot; ) + xlab(\u0026quot;post theme\u0026quot;) + ylab(\u0026quot;time to read post\u0026quot;) + scale_fill_manual(values = c(pink, olive)) + scale_color_manual(values = c(pink, olive)) + theme_merb() + theme(#legend.position = \u0026quot;none\u0026quot;, axis.text = element_text(size = 15), axis.title = element_text(size = 20)) plot_violin  legend plot_leg \u0026lt;- grid.arrange(cowplot::get_legend(plot_topic), cowplot::get_legend(plot_point_infin), widths = c(15, 85), layout_matrix = rbind(c(3, 2), c(3, 1)) )  text boxes header header \u0026lt;- ggplot() + annotate(geom = \u0026quot;text\u0026quot;, y = 3.25, x = 1, size = 10, hjust = .8, family = \u0026quot;Roboto\u0026quot;, color = colors_merb_seq[2], label = \u0026quot;what the use of\u0026quot; ) + annotate(geom = \u0026quot;text\u0026quot;, y = 2, x= 1, size = 30, family = \u0026quot;Share Tech Mono\u0026quot;, color = pink, alpha = 0.05, hjust = 0.5, label=\u0026quot;infinitives\u0026quot; ) + annotate(geom = \u0026quot;text\u0026quot;, y = 2, x= 1, size = 15, family = \u0026quot;Share Tech Mono\u0026quot;, color = colors_merb_seq[5], hjust = 0.5, label=\u0026quot;infinitives\u0026quot; ) + annotate(geom = \u0026quot;text\u0026quot;, y = 1, x = 1, size = 10, family = \u0026quot;Roboto\u0026quot;, color = colors_merb_seq[2], hjust = .2, label = \u0026quot;says about a Medium post\u0026quot; ) + ylim(0,4) + theme_void() + theme( plot.background = element_rect(color = \u0026quot;#191919\u0026quot;, fill = olive, size = 5) ) header  definition sidebar def_sidebar \u0026lt;- ggplot() + ylim(-2,2) + xlim(-2,2) + annotate(\u0026quot;text\u0026quot;, x = -2, y = 1.5, hjust = 0, vjust = 1, lineheight = 0.75, family = \u0026quot;Roboto\u0026quot;, size = 20, alpha = 0.1, color = \u0026quot;#D9B0AC\u0026quot;, label = \u0026quot;infinitive\u0026quot;) + annotate(\u0026quot;text\u0026quot;, x = -2, y = -1, hjust = 0, vjust = 1, lineheight = 0.75, family = \u0026quot;Roboto\u0026quot;, size = 20, alpha = 0.1, color = \u0026quot;#D9B0AC\u0026quot;, label = \u0026quot;Medium\u0026quot;) + annotate(\u0026quot;text\u0026quot;, x = -1.5, y = 2, hjust = 0, vjust = 1, lineheight = 0.75, family = \u0026quot;Roboto\u0026quot;, size = 4.8, color = \u0026quot;white\u0026quot;, label = paste0( str_wrap(\u0026quot;infinitive: a verb form found in many languages that functions as a noun or is used with auxiliary verbs, and that names the action or state without specifying the subject: “to come”, “to be”, “to want”\u0026quot;, 29), \u0026quot;\\n\u0026quot;, \u0026quot;\\n\u0026quot;, \u0026quot;\\n\u0026quot;, str_wrap(\u0026quot;Medium: an online publishing platform developed as a long-form alternative to twitter.\u0026quot;, 29)) ) + theme_void() + theme( plot.background = element_rect(fill = \u0026quot;#222220\u0026quot; , color = \u0026quot;#191919\u0026quot;, size = 2) ) def_sidebar  top sidebar top_sidebar \u0026lt;- ggplot() + ylim(-2,2) + xlim(-2,2) + annotate(\u0026quot;text\u0026quot;, x = -2, y = 2, hjust = 0, vjust = 1, lineheight = 0.75, family = \u0026quot;Roboto\u0026quot;, size = 5, color = \u0026quot;white\u0026quot;, label = paste0( str_wrap(\u0026quot;Infinitives are used to express wants and desires. When an author uses an infinitive in the title of an article, they are making a promise to the reader about what the reader will learn: 'to build', 'to solve', 'to disrupt'. The figure to the left shows the relationship between how often an infinitive is used in the titles of Medium posts (on the topics of data science) and the number of claps (likes) the post received.\u0026quot;, 32), \u0026quot;\\n\u0026quot;,\u0026quot;\\n\u0026quot;, str_wrap(\u0026quot;Compared to verbs alone, infinitives say a lot more about the content of an article, which you can see in the lists below. They show the 'most-clapped' verbs or infinitives that are found in at least 5 article titles:\u0026quot;, 32) ) )+ theme_void() + theme( plot.background = element_rect(fill = \u0026quot;#20261d\u0026quot; , color = \u0026quot;#191919\u0026quot;, size = 2) ) top_sidebar  bottom sidebar bot_sidebar \u0026lt;- ggplot() + ylim(-2,2) + xlim(-2,2) + annotate(\u0026quot;text\u0026quot;, x = -2, y = 2, hjust = 0, vjust = 1, lineheight = 0.75, family = \u0026quot;Share Tech Mono\u0026quot;, size = 6, color = \u0026quot;#D9B0AC\u0026quot;, label = \u0026quot;build vs break\u0026quot; ) + annotate(\u0026quot;text\u0026quot;, x = -2, y = 1.5, hjust = 0, vjust = 1, lineheight = 0.75, family = \u0026quot;Roboto\u0026quot;, size = 5, color = \u0026quot;white\u0026quot;, label = paste0( str_wrap(\u0026quot;Infinitives like 'build' and 'create' are overused in Medium post titles, and have little impact, while 'disrupt' and 'break' see far more claps on average. Comparing these types of posts one can see that 'breaking' posts are usually shorter (a), have more emotional content (b), and are less likely to have highly specific tags (c)\u0026quot;, 32) ) ) + theme_void() + theme( plot.background = element_rect(fill = \u0026quot;#222220\u0026quot; , color = \u0026quot;#191919\u0026quot;, size = 2) ) bot_sidebar  footer footer \u0026lt;- ggplot() + ylim(-2,2) + xlim(-2,2) + annotate(\u0026quot;text\u0026quot;, x = 0, y = 0, hjust = .5, vjust = .5, lineheight = 0.75, family = \u0026quot;Roboto\u0026quot;, size = 4, color = \u0026quot;#191919\u0026quot;, label = paste0( \u0026quot;A #TidyTuesday adventure + Data from Kaggle.com + Design and and analysis by @TannerKoomar\u0026quot;, \u0026quot;\\n\u0026quot;, \u0026quot;Code at https://github.com/tkoomar/tidytuesday/blob/master/work/2018-12-04.md\u0026quot; ) ) + theme_void() + theme( plot.background = element_rect(fill = olive , color = \u0026quot;#191919\u0026quot;, size = 2) ) footer  stitch it together png(\u0026quot;2018-12-04_final_plot.png\u0026quot;, width = 1200, height = 1600, res = 144, bg = \u0026quot;#191919\u0026quot;) grid.arrange(header, def_sidebar, plot_point_infin + theme(legend.position = 'none'), top_sidebar, plot_leg, infin_list, verb_list, plot_violin + theme(legend.position = 'none') + labs(tag = \u0026quot;(a)\u0026quot;), plot_sent + theme(legend.position = 'none') + labs(tag = \u0026quot;(b)\u0026quot;), plot_topic + theme(legend.position = 'none')+ labs(tag = \u0026quot;(c)\u0026quot;), bot_sidebar, footer, heights = c(15, 30, 20, 30, 30, 5), layout_matrix = rbind(c(1,1,1,1), c(2,3,3,4), c(5,3,3,4), c(11,9,9,6), c(8,10,10,7), c(12,12,12,12)) ) dev.off()  ## png ## 2  The final Plot ","date":1546646400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546646400,"objectID":"6775d487678424ef4ecc976043fc09b4","permalink":"/post/2019-01-05-tt-medium/","publishdate":"2019-01-05T00:00:00Z","relpermalink":"/post/2019-01-05-tt-medium/","section":"post","summary":"Some light web-scraping and natual language processing reveals how different parts of speech may hint at an author\u0026rsquo;s intent (and impact).\n","tags":["R","nlp","web scraping"],"title":"Tidy Tuesday: Infinitives in Medium Posts","type":"post"},{"authors":null,"categories":["tidytuesday"],"content":"knitr::opts_chunk$set(echo = TRUE) library(tidyverse) ## ── Attaching packages ─────────────────────────────────────────────────── tidyverse 1.3.0 ── ## ✔ ggplot2 3.2.1 ✔ purrr 0.3.3 ## ✔ tibble 2.1.3 ✔ dplyr 0.8.3 ## ✔ tidyr 1.0.0 ✔ stringr 1.4.0 ## ✔ readr 1.3.1 ✔ forcats 0.4.0 ## ── Conflicts ────────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() library(geojsonio) ## ## Attaching package: \u0026#39;geojsonio\u0026#39; ## The following object is masked from \u0026#39;package:base\u0026#39;: ## ## pretty library(showtext) ## for google fonts ## Loading required package: sysfonts ## Loading required package: showtextdb dat_death \u0026lt;- read_csv(\u0026quot;https://github.com/rfordatascience/tidytuesday/raw/master/data/2018/2018-11-13/malaria_deaths.csv\u0026quot;) ## Parsed with column specification: ## cols( ## Entity = col_character(), ## Code = col_character(), ## Year = col_double(), ## `Deaths - Malaria - Sex: Both - Age: Age-standardized (Rate) (per 100,000 people)` = col_double() ## ) dat_age \u0026lt;- read_csv(\u0026quot;https://github.com/rfordatascience/tidytuesday/raw/master/data/2018/2018-11-13/malaria_deaths_age.csv\u0026quot;) ## Warning: Missing column names filled in: \u0026#39;X1\u0026#39; [1] ## Parsed with column specification: ## cols( ## X1 = col_double(), ## entity = col_character(), ## code = col_character(), ## year = col_double(), ## age_group = col_character(), ## deaths = col_double() ## ) dat_inc \u0026lt;- read_csv(\u0026quot;https://github.com/rfordatascience/tidytuesday/raw/master/data/2018/2018-11-13/malaria_inc.csv\u0026quot;) ## Parsed with column specification: ## cols( ## Entity = col_character(), ## Code = col_character(), ## Year = col_double(), ## `Incidence of malaria (per 1,000 population at risk) (per 1,000 population at risk)` = col_double() ## ) Let’s look at the change over time (increase or in)\ndat_death \u0026lt;- dat_death %\u0026gt;% filter(Year \u0026gt;= 1995, Year \u0026lt;= 2015) %\u0026gt;% mutate(lustrum = cut_number(Year, 4)) %\u0026gt;% group_by(Code, lustrum) %\u0026gt;% summarize( \u0026quot;malaria death rate\u0026quot; = cor(`Deaths - Malaria - Sex: Both - Age: Age-standardized (Rate) (per 100,000 people)`, Year, method = \u0026quot;p\u0026quot; ) ) dat_inc \u0026lt;- dat_inc %\u0026gt;% filter(`Incidence of malaria (per 1,000 population at risk) (per 1,000 population at risk)` != 0) %\u0026gt;% group_by(Code) %\u0026gt;% rename( \u0026quot;malaria incidence rate\u0026quot; = `Incidence of malaria (per 1,000 population at risk) (per 1,000 population at risk)` ) dat_age \u0026lt;- dat_age %\u0026gt;% filter(year \u0026gt;= 1995, year \u0026lt;= 2015, deaths != 0) %\u0026gt;% mutate(lustrum = cut_number(year, 4)) %\u0026gt;% group_by(code, lustrum, age_group) %\u0026gt;% rename(Code = \u0026quot;code\u0026quot;, Year = \u0026quot;year\u0026quot;) %\u0026gt;% summarize( \u0026quot;deaths per age\u0026quot; = cor(deaths, Year, method = \u0026quot;p\u0026quot; ) ) get map of world world \u0026lt;- geojson_read(\u0026#39;https://github.com/simonepri/geo-maps/releases/download/v0.6.0/countries-land-10km.geo.json\u0026#39;, what = \u0026quot;sp\u0026quot;) w \u0026lt;- sf::st_as_sf(world) %\u0026gt;% rename(\u0026quot;Code\u0026quot; = \u0026quot;A3\u0026quot;) dat_w \u0026lt;- w %\u0026gt;% left_join(dat_death) %\u0026gt;% left_join(dat_age) %\u0026gt;% left_join(dat_inc) dat_w \u0026lt;- dat_w %\u0026gt;% mutate( lustrum = case_when( lustrum == \u0026quot;[1995,2000]\u0026quot; ~ \u0026quot;1995 - 2000\u0026quot;, lustrum == \u0026quot;(2000,2005]\u0026quot; ~ \u0026quot;2000 - 2005\u0026quot;, lustrum == \u0026quot;(2005,2010]\u0026quot; ~ \u0026quot;2005 - 2010\u0026quot;, lustrum == \u0026quot;(2010,2015]\u0026quot; ~ \u0026quot;2010 - 2015\u0026quot; ) ) %\u0026gt;% filter(!is.na(lustrum)) font_add_google(\u0026quot;Josefin Sans\u0026quot;) showtext_auto(144) malaria_plot \u0026lt;- dat_w %\u0026gt;% ggplot( aes( fill = cut_width(`malaria death rate`, center = 0, width = 0.5) ) ) + geom_sf(aes(color = is.na(`malaria death rate`)))+ coord_sf(ndiscr = 0) + theme_void() + scale_color_manual(values = c(\u0026quot;TRUE\u0026quot; = \u0026quot;#d9e8f5\u0026quot;, \u0026quot;FALSE\u0026quot; = NA), guide = \u0026#39;none\u0026#39;) + scale_fill_brewer(palette = \u0026quot;RdYlGn\u0026quot;, direction = -1, labels = c(\u0026quot;decrease\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;increase\u0026quot;, \u0026quot;\u0026quot;), guide = guide_legend( label.position = \u0026quot;left\u0026quot;, override.aes = list(color = NA)) ) + theme( plot.background = element_rect(fill = \u0026quot;#c9dff2\u0026quot;), legend.title = element_blank(), legend.text = element_text(), legend.key = element_blank(), text = element_text(family = \u0026quot;Josefin Sans\u0026quot;, size = 18) ) + ggtitle(\u0026quot;annual change in malaria mortality rates from 1995 to 2015\u0026quot;, \u0026quot;A #TidyTuesday adventure by @TannerKoomar\u0026quot;) + facet_wrap(. ~ lustrum, ncol = 2) malaria_plot  ","date":1544572800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1544572800,"objectID":"805c7571f1fc266749f1304e3547388a","permalink":"/post/2018-12-12-tt-malaria/","publishdate":"2018-12-12T00:00:00Z","relpermalink":"/post/2018-12-12-tt-malaria/","section":"post","summary":"\n\n\n","tags":["R","map"],"title":"Tidy Tuesday: Malaria","type":"post"},{"authors":["Tanner Koomar"],"categories":null,"content":"","date":1543622400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543622400,"objectID":"7b26a5827b9a16a17ce7db4094b86595","permalink":"/publication/2018-case-study-asd/","publishdate":"2018-12-01T00:00:00Z","relpermalink":"/publication/2018-case-study-asd/","section":"publication","summary":"In this family-bsed case study, we discovered elevated elevatd levels of common *and* rare variant polygenic risk via whole genome sequencing.","tags":["autism","whole genome sequencing","polygenic risk"],"title":"Whole-genome sequencing in a family with twin boys with autism and intellectual disability suggests multimodal polygenic risk","type":"publication"},{"authors":null,"categories":["tidytuesday"],"content":"\ndat \u0026lt;- read_csv(\u0026quot;https://github.com/rfordatascience/tidytuesday/raw/master/data/2018/2018-11-20/thanksgiving_meals.csv\u0026quot;) ## Parsed with column specification: ## cols( ## .default = col_character(), ## id = col_double() ## ) ## See spec(...) for full column specifications. Boy is this data messy! Lets relabel and organize it a bit.\ndat \u0026lt;- dat %\u0026gt;% filter(is.na(dat) %\u0026gt;% rowSums() \u0026lt; 50) %\u0026gt;% select(-id, -pie13, -dessert11, -side15, -contains(\u0026quot;Other\u0026quot;)) %\u0026gt;% mutate( \u0026quot;number of\\nkinds of pie\u0026quot; = select(., contains(\u0026quot;pie\u0026quot;)) %\u0026gt;% {!is.na(.)} %\u0026gt;% rowSums(), \u0026quot;total number\\nof sides\u0026quot; = select(., contains(\u0026quot;side\u0026quot;)) %\u0026gt;% {!is.na(.)} %\u0026gt;% rowSums(), \u0026quot;number of\\n non-pie desserts\u0026quot; = select(., contains(\u0026quot;dessert\u0026quot;)) %\u0026gt;% {!is.na(.)} %\u0026gt;% rowSums() ) %\u0026gt;% mutate( family_income = factor(family_income, levels = c(\u0026quot;$0 to $9,999\u0026quot; , \u0026quot;$10,000 to $24,999\u0026quot;, \u0026quot;$25,000 to $49,999\u0026quot;, \u0026quot;$50,000 to $74,999\u0026quot;, \u0026quot;$75,000 to $99,999\u0026quot;, \u0026quot;$100,000 to $124,999\u0026quot;, \u0026quot;$150,000 to $174,999\u0026quot;, \u0026quot;$175,000 to $199,999\u0026quot;, \u0026quot;$200,000 and up\u0026quot;, \u0026quot;Prefer not to answer\u0026quot;, \u0026quot;NA\u0026quot;), ordered = T) ) Odds Ratio plot_or \u0026lt;- dat %\u0026gt;% transmute( urban = community_type == \u0026quot;Urban\u0026quot;, not_urban = community_type != \u0026quot;Urban\u0026quot;, parade = !is.na(watch_program), under30 = dat$age == \u0026quot;18 - 29\u0026quot;, over60 = dat$age == \u0026quot;60+\u0026quot;, female = dat$gender == \u0026quot;Female\u0026quot;, pray = dat$prayer == \u0026quot;Yes\u0026quot; ) %\u0026gt;% #select(prayer, female, friendsgiving, urban, not_urban, parade, under30, over60) %\u0026gt;% map(function(x){ out \u0026lt;- table(gravy = dat$gravy, foo = x) %\u0026gt;% fisher.test(conf.level = 0.6827) out \u0026lt;- c(out$estimate, lower = out$conf.int[1], upper = out$conf.int[2]) return(out) }) %\u0026gt;% as.data.frame() %\u0026gt;% rownames_to_column() %\u0026gt;% gather(key, value, -rowname) %\u0026gt;% spread(rowname, value) %\u0026gt;% ggplot(aes(y = key, x = `odds ratio`))+ geom_errorbarh(aes(xmin = lower, xmax = upper), size = .45, color = \u0026quot;#899DA4\u0026quot;, height = 0.75) + geom_point(size = 4, color = \u0026quot;#DC863B\u0026quot;) + geom_vline(xintercept = 1, lty = 2, lwd = 1, color = \u0026quot;#C93312\u0026quot;) + scale_x_continuous( sec.axis = sec_axis(~ ., breaks = c(0.65, 1.8), labels = c(\u0026quot;less likely\\nto have gravy\u0026quot;, \u0026quot;more likely\\nto have gravy\u0026quot;)) ) + scale_y_discrete(labels = c(\u0026quot;pray\u0026quot; = \u0026quot;pray at dinner\u0026quot;, \u0026quot;urban\u0026quot; = \u0026quot;city dwellers\u0026quot;, \u0026quot;not_urban\u0026quot; = \u0026quot;suburban or\\ncountry dwellers\u0026quot;, \u0026quot;female\u0026quot; = \u0026quot;women\u0026quot;, \u0026quot;under30\u0026quot; = \u0026quot;people under 30\u0026quot;, \u0026quot;over60\u0026quot; = \u0026quot;people over 60\u0026quot;, \u0026quot;parade\u0026quot; = \u0026quot;watch the\\nMacy\u0026#39;s parade\u0026quot;) ) + ylab(\u0026quot;\u0026quot;) + xlab(\u0026quot;odds ratio\u0026quot;) + theme_minimal() + theme( text = element_text(family = \u0026quot;Poppins\u0026quot;), axis.text.x.top = element_text(size = 15, lineheight = 0.75), axis.text.y = element_text(size = 10, lineheight = 0.7), axis.ticks.x.top = element_blank(), plot.background = element_rect(color = NA, fill = \u0026quot;#fcf7e8\u0026quot;), panel.background = element_rect(color = NA, \u0026quot;#faefd1\u0026quot;), panel.grid = element_line(color = \u0026quot;#fcf7e8\u0026quot;), panel.grid.minor = element_blank() ) plot_or  Violin Plots plot_totals \u0026lt;- dat %\u0026gt;% filter(!is.na(gravy)) %\u0026gt;% select(contains(\u0026quot;number\u0026quot;), gravy) %\u0026gt;% gather(key, value, -gravy) %\u0026gt;% mutate(gravy = case_when( gravy == \u0026quot;Yes\u0026quot; ~ \u0026quot;gravy\u0026quot;, gravy == \u0026quot;No\u0026quot; ~ \u0026quot;no gravy\u0026quot; )) %\u0026gt;% ggplot(aes(x = gravy, y = value, fill = gravy)) + scale_fill_manual(values = c(\u0026quot;gravy\u0026quot; = \u0026quot;#DC863B\u0026quot;, \u0026quot;no gravy\u0026quot; = \u0026quot;#F8AFA8\u0026quot;)) + geom_violin(alpha = 0.75, color = NA) + stat_summary(fun.y = mean, fun.ymin = function(x){ quantile(x, probs = 0.25) }, fun.ymax = function(x){ quantile(x, probs = 0.75) }, color = \u0026quot;#74A089\u0026quot;, size = 0.5 ) + facet_wrap(~ key) + theme_minimal() + theme(legend.position = \u0026#39;none\u0026#39;, text = element_text(family = \u0026quot;Poppins\u0026quot;), strip.text = element_text(size = 12, lineheight = 0.75), axis.text.x.top = element_text(size = 15), axis.text.x = element_text(size = 12), axis.title.x = element_blank(), axis.ticks.x.top = element_blank(), axis.text.y = element_blank(), axis.title.y = element_blank(), plot.background = element_rect(color = NA, fill = \u0026quot;#fcf7e8\u0026quot;), panel.background = element_rect(color = NA, \u0026quot;#faefd1\u0026quot;), panel.grid = element_line(color = \u0026quot;#fcf7e8\u0026quot;), panel.grid.minor = element_blank() ) plot_totals  Line Chart of Income plot_income \u0026lt;- dat %\u0026gt;% filter(family_income != \u0026quot;NA\u0026quot; \u0026amp; family_income != \u0026quot;Prefer not to answer\u0026quot;) %\u0026gt;% group_by(family_income) %\u0026gt;% summarize( gravy = mean(gravy == \u0026quot;Yes\u0026quot;, na.rm = T), gravy_sd = sqrt(gravy*(1-gravy)/n()) ) %\u0026gt;% ungroup() %\u0026gt;% ggplot(aes(y = gravy, x = family_income, group = 1, color = family_income)) + geom_line(size = 3) + geom_point(size = 6) + geom_errorbar(aes(ymin = gravy - gravy_sd, ymax = gravy + gravy_sd), size = .25, width = .15) + scale_color_manual(values = wesanderson::wes_palette(\u0026quot;Royal2\u0026quot;, n = 9, type = \u0026quot;c\u0026quot;) ) + scale_x_discrete(breaks = c(\u0026quot;$0 to $9,999\u0026quot; ,\u0026quot;$75,000 to $99,999\u0026quot;, \u0026quot;$200,000 and up\u0026quot;), labels = c(\u0026quot;$0 to\\n$9,999\u0026quot; ,\u0026quot;$75,000 to\\n$99,999\u0026quot;, \u0026quot;$200,000\\n and up\u0026quot;)) + ggtitle(\u0026quot;annual family income\u0026quot;) + ylab(\u0026quot;probability of having gravy\u0026quot;) + theme_minimal() + theme( legend.position = \u0026#39;none\u0026#39;, text = element_text(family = \u0026quot;Poppins\u0026quot;), axis.text.x = element_text(size = 12), axis.title.x = element_blank(), axis.ticks.x.top = element_blank(), axis.text.y = element_text(size = 12), axis.title.y = element_text(size = 15), plot.background = element_rect(color = NA, fill = \u0026quot;#fcf7e8\u0026quot;), panel.background = element_rect(color = NA, fill = \u0026quot;#faefd1\u0026quot;), panel.grid = element_line(color = \u0026quot;#fcf7e8\u0026quot;), panel.grid.minor = element_blank(), plot.title = element_text(size = 15, hjust = 0.5) ) plot_income  Text Boxes header \u0026lt;- ggplot() + annotate(geom = \u0026quot;text\u0026quot;, y = 3.15, x = 2, size = 50, family = \u0026quot;Pacifico\u0026quot;, color = \u0026quot;#fcf7e8\u0026quot;, label=\u0026quot;gravy\u0026quot;) + annotate(geom = \u0026quot;text\u0026quot;, y = 3.25, x = 2, size = 5, family = \u0026quot;Poppins\u0026quot;, color = \u0026quot;#74A089\u0026quot;, label = \u0026quot;what your thanksgiving\u0026quot; ) + annotate(geom = \u0026quot;text\u0026quot;, y = 2.5, x= 2, size = 25, family = \u0026quot;Pacifico\u0026quot;, color = \u0026quot;#DC863B\u0026quot;, label=\u0026quot;gravy\u0026quot;) + annotate(geom = \u0026quot;text\u0026quot;, y = .35, x = 2, size = 5,family = \u0026quot;Poppins\u0026quot;, color = \u0026quot;#74A089\u0026quot;, hjust = .6, label = \u0026quot;says about you\u0026quot;) + ylim(0,4) + theme_void() + theme( plot.background = element_rect(color = \u0026quot;#fcf7e8\u0026quot;, fill = \u0026quot;#faefd1\u0026quot;, size = 5) ) header midbar1 \u0026lt;- ggplot() + ylim(-2,2) + xlim(-2,2) + annotate(\u0026quot;text\u0026quot;, x = -2, y = -2, hjust = 0, vjust = 0, lineheight = 0.75, family = \u0026quot;Poppins\u0026quot;, size = 4, color = \u0026quot;#899DA4\u0026quot;, label = str_wrap(\u0026quot;A dinner accompanied by congealed broth is a symbol of status and abundance. Below, the presence of gravy at a Thanksgiving meal goes hand-in-hand with a greater variety of both side dishes and pies.\u0026quot;, 70) ) + theme_void() + theme( plot.background = element_rect(fill = \u0026quot;#fcf7e8\u0026quot;, color = NA) ) midbar2 \u0026lt;- ggplot() + ylim(-2,2) + xlim(-2,2) + annotate(\u0026quot;text\u0026quot;, x = -2, y = -2, hjust = 0, vjust = 0, lineheight = 0.75, family = \u0026quot;Poppins\u0026quot;, size = 4, color = \u0026quot;#899DA4\u0026quot;, label = str_wrap(\u0026quot;Eating concentrated meat juice is also a luxurious marker of wealth. The probability that a family will have gravy at a Thanksgiving meal increases markedly with annual income.\u0026quot;, 70)) + theme_void() + theme( plot.background = element_rect(fill = \u0026quot;#fcf7e8\u0026quot;, color = NA) ) midbar1  midbar2 sidebar \u0026lt;- ggplot() + ylim(-2,2) + xlim(-2,2) + annotate(\u0026quot;text\u0026quot;, x = -2, y = 2, hjust = 0, vjust = 1, lineheight = 1.05, family = \u0026quot;Poppins\u0026quot;, size = 4.4, color = \u0026quot;#899DA4\u0026quot;, label = str_wrap(\u0026quot;Gravy is truly the bellwether of the thanksgiving table. If you abstain from gravy, you are much more likely to live in a city, identify as a woman, and be younger than 30. Gravy-eaters, on the other hand, are much more likely to have an AARP membership, watch the Thanksgiving day parade, pray before dinner, and live outside or an urban center.\u0026quot;, 29)) + theme_void() + theme( plot.background = element_rect(fill = \u0026quot;#faefd1\u0026quot;, color = NA) ) sidebar footnote \u0026lt;- ggplot() + ylim(-2,2) + xlim(-2,2) + annotate(\u0026quot;text\u0026quot;, x = 2, y = -2, hjust = 1, vjust = 0, lineheight = 0.75, family = \u0026quot;Poppins\u0026quot;, size = 2.75, color = \u0026quot;#899DA4\u0026quot;, label = paste(\u0026quot;a #TidyTuesday adventure\\ndesign by @TannerKoomar\\ndata from FiveThirtyEight\\ncolor scheme from karthik/wesanderson\u0026quot;)) + theme_void() + theme( plot.background = element_rect(fill = \u0026quot;#fcf7e8\u0026quot;, color = NA) ) footnote  Plots Assemble! final_plot \u0026lt;- grid.arrange(header, midbar1, midbar2, ggplotGrob(plot_totals), ggplotGrob(plot_income), ggplotGrob(plot_or), sidebar, footnote, heights = c(.15, .075, .35, .025, .325, .075), layout_matrix = rbind(c(1,1,1,1), c(2,2,3,3), c(4,4,5,5), c(NA,NA,NA,NA), c(6,6,6,7), c(6,6,6,8)) ) ## Get rid of that ugly white bar in the middle. . . cowplot::ggdraw(final_plot) + theme(plot.background = element_rect(fill = \u0026quot;#fcf7e8\u0026quot;))  ","date":1542672000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542672000,"objectID":"37ba72e2c29a7fd786a8cc8423a967b9","permalink":"/post/2018-11-20-tt-gravy/","publishdate":"2018-11-20T00:00:00Z","relpermalink":"/post/2018-11-20-tt-gravy/","section":"post","summary":" Learn what your gravy eating habits say about you with a fun fall color scheme from the wesanderson package. ","tags":["R","holiday","gridExtra"],"title":"Tidy Tuesday: Thanksgiving Gravy","type":"post"},{"authors":null,"categories":["tidytuesday"],"content":"Load Data dat \u0026lt;- read_csv(\u0026quot;https://github.com/rfordatascience/tidytuesday/raw/master/data/2018/2018-11-06/us_wind.csv\u0026quot;) ## Parsed with column specification: ## cols( ## .default = col_double(), ## faa_ors = col_character(), ## faa_asn = col_character(), ## t_state = col_character(), ## t_county = col_character(), ## t_fips = col_character(), ## p_name = col_character(), ## t_manu = col_character(), ## t_model = col_character(), ## t_img_date = col_character(), ## t_img_srce = col_character() ## ) ## See spec(...) for full column specifications. ## get all the missing data to NA dat \u0026lt;- dat %\u0026gt;% mutate_all(.funs = funs(replace(., . %in% c(-9999, \u0026quot;missing\u0026quot;), NA))) ## Warning: funs() is soft deprecated as of dplyr 0.8.0 ## Please use a list of either functions or lambdas: ## ## # Simple named list: ## list(mean = mean, median = median) ## ## # Auto named with `tibble::lst()`: ## tibble::lst(mean, median) ## ## # Using lambdas ## list(~ mean(., trim = .2), ~ median(., na.rm = TRUE)) ## This warning is displayed once per session. ## drop rows and columns with high missing dat.comp \u0026lt;- dat %\u0026gt;% select_if( function(x){sum(is.na(x))/length(x) \u0026lt; .15}) %\u0026gt;% filter(rowMeans(is.na(.)) \u0026lt; 0.15) ## get info at project level dat.p.num \u0026lt;- dat.comp %\u0026gt;% group_by(p_name) %\u0026gt;% select_if(is.numeric) %\u0026gt;% select(-case_id) %\u0026gt;% summarise_all(.funs = function(x){mean(x, na.rm = T)}) %\u0026gt;% ungroup %\u0026gt;% select(-p_name) %\u0026gt;% filter(rowSums(is.na(.)) == 0) %\u0026gt;% filter(xlong \u0026lt; 100 \u0026amp; xlong \u0026gt; -125 \u0026amp; ylat \u0026gt; 20) %\u0026gt;% ## remove some geographic outliers filter(t_cap \u0026gt; 0 \u0026amp; t_cap \u0026lt; 6000)   Reduce Dimensionality Do a PCA Looks like PC1 makes up the bul of the difference, and it is due to turbine rotor sweep area\ndat.pca \u0026lt;- prcomp(dat.p.num, center = TRUE, scale. = TRUE) summary(dat.pca) ## Importance of components: ## PC1 PC2 PC3 PC4 PC5 PC6 PC7 ## Standard deviation 2.3420 1.3762 1.00832 0.98379 0.94979 0.86079 0.7040 ## Proportion of Variance 0.4571 0.1578 0.08473 0.08065 0.07517 0.06175 0.0413 ## Cumulative Proportion 0.4571 0.6149 0.69963 0.78028 0.85546 0.91720 0.9585 ## PC8 PC9 PC10 PC11 PC12 ## Standard deviation 0.53133 0.35791 0.27616 0.10600 0.01020 ## Proportion of Variance 0.02353 0.01067 0.00636 0.00094 0.00001 ## Cumulative Proportion 0.98202 0.99270 0.99905 0.99999 1.00000 dat.pca$rotation %\u0026gt;% as.data.frame() %\u0026gt;% rownames_to_column() %\u0026gt;% ggplot(aes(y = PC1, x = rowname)) + geom_col()  Some plots dat.p.num %\u0026gt;% bind_cols(as.tibble(dat.pca$x)) %\u0026gt;% ggplot(aes(x = xlong, ylat, color = PC1, size = p_cap, alpha = t_cap)) + scale_color_viridis_c() + geom_point() ## Warning: `as.tibble()` is deprecated, use `as_tibble()` (but mind the new semantics). ## This warning is displayed once per session.  Cluster ## Use the PCs that explain 95% of the variance dat.k \u0026lt;- dat.pca$x %\u0026gt;% as.tibble %\u0026gt;% select(1:7) %\u0026gt;% mutate( k2 = kmeans(., 2)$cluster, k3 = kmeans(., 3)$cluster, k4 = kmeans(., 4)$cluster, k5 = kmeans(., 5)$cluster, k6 = kmeans(., 6)$cluster ) %\u0026gt;% bind_cols(dat.p.num)  Cluster Plots dat.k %\u0026gt;% ggplot(aes(x = xlong, ylat, color = as.character(k6), size = p_cap, alpha = t_cap)) + scale_color_brewer(palette = \u0026quot;Dark2\u0026quot;) + geom_point() dat.k %\u0026gt;% ggplot(aes(x = xlong, ylat, color = as.character(k6), size = p_cap, alpha = t_cap)) + scale_color_brewer(palette = \u0026quot;Dark2\u0026quot;)+ geom_point() + facet_wrap(~ as.character(k6), nrow = 3)   Make a pretty map under the data library(ggmap) invert \u0026lt;- function(M) { i \u0026lt;- function(x){rgb(t(255-col2rgb(x))/255)} m \u0026lt;- M %\u0026gt;% apply(2, i) %\u0026gt;% as.raster() class(m) \u0026lt;- class(M) attr(m, \u0026quot;bb\u0026quot;) \u0026lt;- attr(M, \u0026quot;bb\u0026quot;) return(m) } us \u0026lt;- c(left = -125, bottom = 25.75, right = -67, top = 49) m \u0026lt;- get_stamenmap(us, zoom = 5, maptype = \u0026quot;toner-lite\u0026quot;) ggmap(invert(m))  Plots plot.points \u0026lt;- ggmap(invert(m), extent = \u0026#39;device\u0026#39;) + geom_point(aes(x = xlong, y = ylat, color = as.character(k6), size = p_cap, alpha = t_cap), data = dat.k, pch = 18) + scale_color_brewer(palette = \u0026quot;Set1\u0026quot;) + facet_wrap(~k6, ncol = 1) + theme_void() + theme(legend.position = \u0026#39;none\u0026#39;, strip.text = element_blank()) + theme(plot.background = element_rect(fill = \u0026quot;black\u0026quot;, color = \u0026quot;black\u0026quot;), panel.background = element_rect(fill = NULL)) plot.density \u0026lt;- ggmap(invert(m), extent = \u0026#39;device\u0026#39;) + stat_density2d(aes(x = xlong, y = ylat, alpha = ..level.., fill = as.character(k6), color = NULL), data = dat.k, geom = \u0026quot;polygon\u0026quot;) + scale_fill_brewer(palette = \u0026quot;Set1\u0026quot;) + facet_wrap(~k6, ncol = 1) + theme_void() + theme(legend.position = \u0026#39;none\u0026#39;, strip.text = element_blank()) + theme(plot.background = element_rect(fill = \u0026quot;black\u0026quot;, color = \u0026quot;black\u0026quot;), panel.background = element_rect(fill = NULL)) plot.all \u0026lt;- ggmap(invert(m), extent = \u0026#39;device\u0026#39;) + geom_point(aes(x = xlong, y = ylat, color = as.character(k6), size = p_cap, alpha = t_cap), data = dat.k, pch = 18) + scale_color_brewer(palette = \u0026quot;Set1\u0026quot;) + guides( size = guide_legend(title = \u0026quot;project capacity\u0026quot;,title.position = \u0026#39;top\u0026#39;, override.aes = list(color = \u0026quot;white\u0026quot;)), alpha = guide_legend(title = \u0026quot;turbine capacity\u0026quot;,title.position = \u0026#39;top\u0026#39;, override.aes = list(color = \u0026quot;white\u0026quot;, size = 4)), color = guide_legend(title = \u0026#39;cluster\u0026#39;, title.position = \u0026#39;top\u0026#39;, override.aes = list(size = 4)) ) + ggtitle(\u0026quot;US Wind Turbine Projects\u0026quot;, \u0026quot; a #tidytuesday adventure\u0026quot;) + theme_void() + theme(title = element_text(color = \u0026#39;white\u0026#39;), legend.position = \u0026#39;bottom\u0026#39;, legend.background = element_blank(), legend.text = element_text(color = \u0026quot;white\u0026quot;), legend.title = element_text(color = \u0026quot;white\u0026quot;), legend.key = element_blank(), axis.text = element_blank(), axis.title = element_blank(), plot.background = element_rect(fill = \u0026quot;black\u0026quot;, color = \u0026quot;black\u0026quot;), panel.background = element_rect(fill = NULL)) Squish together library(cowplot) ## ## ******************************************************** ## Note: As of version 1.0.0, cowplot does not change the ## default ggplot2 theme anymore. To recover the previous ## behavior, execute: ## theme_set(theme_cowplot()) ## ******************************************************** ## ## Attaching package: \u0026#39;cowplot\u0026#39; ## The following object is masked from \u0026#39;package:ggmap\u0026#39;: ## ## theme_nothing final.plot \u0026lt;- plot_grid(plotlist = list(plot.points, plot.all, plot.density), nrow = 1, rel_widths = c(.25,1,.25)) ggdraw(final.plot) + theme(plot.background = element_rect(fill = \u0026quot;black\u0026quot;, color = \u0026quot;black\u0026quot;))   ","date":1541462400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541462400,"objectID":"343013edc49f39fcf7b4ffae663cfabb","permalink":"/post/2018-11-06-tt-wind-power/","publishdate":"2018-11-06T00:00:00Z","relpermalink":"/post/2018-11-06-tt-wind-power/","section":"post","summary":" This TidyTuesday we explores wind power throughout the USA with a high-contrast compound figure made with the popular cowplot package.\n","tags":["R","PCA","map","cowplot"],"title":"Tidy Tuesday: USA Wind Power","type":"post"},{"authors":["Tanner Koomar"],"categories":null,"content":"","date":1539820800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539820800,"objectID":"393e6f1886e18cfa56f08cf02a8af83a","permalink":"/publication/2018-forecasd-preprint/","publishdate":"2018-10-18T00:00:00Z","relpermalink":"/publication/2018-forecasd-preprint/","section":"publication","summary":"A new quantitative scoring method for autism-related genes, integrating muliple modalities of data with a random forest model.","tags":["autism","machine learning","random forest","preprint"],"title":"Forecasting autism gene discovery with machine learning and genome-scale data","type":"publication"},{"authors":null,"categories":null,"content":"Well-powered genetic studies of any complex trait require large cohorts. Most current methods of assessing language ability have their roots in clinical practice, and require one on one interaction between a subject and an evaluator. Furthermore, these tests are formulated to be sensitive to variations at the low end of the ability spectrum, but cannot differentiate between individuals of average or better ability.\nThe study of language genetics needs a rapid, scalable assessment which can detect a wide range of ability levels. We are developing a web-based language screening tool composed of a mixture of established and new assessments with an eye to detecting meaningful variation in the language ability of adults.\nBooth Our first deployment of the language screener was in a soundproof booth in a hospital clinic waiting room. We expect participants to return and take screener multiple times, so a mood survey was included to see how mood might be reflected in performance on the various tasks.\nWhy not an app? Web-based tools do pose challenges based on the wide array of hardware and software available to consumers, but every phone, tablet and personal computer has access to a web browser, lowering barriers for entry that are imposed by apps and other single-platform software.\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"cf53058c50fb15a25bc0f64263f7dd32","permalink":"/project/language-screener/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/project/language-screener/","section":"project","summary":"A web-based and battery of language assessments deployed via AWS.","tags":["language genetics","cloud"],"title":"Web-based Language Screener","type":"project"},{"authors":["Tanner Koomar"],"categories":null,"content":"","date":1481760000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1481760000,"objectID":"e9b7bcfe319f67fbe19d212d833687dc","permalink":"/publication/2017-cerebroviz-paper/","publishdate":"2017-05-01T00:00:00Z","relpermalink":"/publication/2017-cerebroviz-paper/","section":"publication","summary":"An R package designed to use SVG drawings of brains as heatmaps, such as for visualizing gene expression data from BrainSpan","tags":["R","data visualization","gene expression"],"title":"cerebroViz: an R package for anatomical visualization of spatiotemporal brain data","type":"publication"},{"authors":null,"categories":null,"content":"In this NIDCD/NICHD-supported project, we are performing whole-genome sequencing of a cohort of Iowa children with language impairment (collected by UI collaborator Bruce Tomblin), where we hope to identify genes and mutations involved in the acquisition and use of language. We hope that research in this area will eventually help to further refine the categorization of language pathology so that therapies can be more targeted and effective.\n","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"b27b5141245e95927bc5f0efc8297eb5","permalink":"/project/language-wgs/","publishdate":"2015-01-01T00:00:00Z","relpermalink":"/project/language-wgs/","section":"project","summary":"Whole genome sequencing of a cohort enriched for language impairment","tags":["language genetics","whole genome sequencing"],"title":"Genetics of Language Ability","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8576ec274c98b3831668a172fa632d80","permalink":"/about/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/about/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8334c3f4a4358949464f152ed873f108","permalink":"/tidytuesday/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/tidytuesday/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]